---
title: 黑灰产从绕过到自建“无约束”的AI模型过程
url: https://forum.butian.net/share/4652
source: 奇安信攻防社区
date: 2025-11-28
fetch_date: 2025-11-29T03:12:21.805428
---

# 黑灰产从绕过到自建“无约束”的AI模型过程

#

[问答](https://forum.butian.net/questions)

*发起*

* [提问](https://forum.butian.net/question/create)
* [文章](https://forum.butian.net/share/create)

[攻防](https://forum.butian.net/community)
[活动](https://forum.butian.net/movable)

Toggle navigation

* [首页 (current)](https://forum.butian.net)
* [问答](https://forum.butian.net/questions)
* [商城](https://forum.butian.net/shop)
* [实战攻防技术](https://forum.butian.net/community)
* [漏洞分析与复现](https://forum.butian.net/articles)
  NEW
* [活动](https://forum.butian.net/movable)
* [摸鱼办](https://forum.butian.net/questions/Play)

搜索

* [登录](https://forum.butian.net/login)
* [注册](https://user.skyeye.qianxin.com/user/register?next=http://forum.butian.net/btlogin)

### 黑灰产从绕过到自建“无约束”的AI模型过程

* [漏洞分析](https://forum.butian.net/topic/48)

市面上主流的大模型服务，都已经建立一套相对成熟的安全架构,这套架构通常可以概括为三层过滤防御体系
1. 输入检测：在用户请求进入模型之前，通过黑白词库、正则表达式和语义分析，拦截掉那些意图明显的恶意问题。
2. 内生安全：模型本身经过安全对齐，通过指令微调和人类反馈强化学习（RLHF），让模型从价值观层面理解并拒绝执行有害指令。
3. 输出检测：在模型生成响应后，再次进行扫描，确保内容合规。。但攻击者依然在生成恶意内容、钓鱼邮件，甚至大规模恶意软件。

想象场景：你的公司投入数百万部署了最先进的AI安全体系——输入过滤、内容审核、RLHF对齐，一应俱全
三层过滤防御体系
1. \*\*输入检测\*\*：在用户请求进入模型之前，通过黑白词库、正则表达式和语义分析，拦截掉那些意图明显的恶意问题。
2. \*\*内生安全\*\*：模型本身经过安全对齐，通过指令微调和人类反馈强化学习（RLHF），让模型从价值观层面理解并拒绝执行有害指令。
3. \*\*输出检测\*\*：在模型生成响应后，再次进行扫描，确保内容合规
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-406893c14df4c0500d517e768bb36a8c6215ef58.png)
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-75914e3c305c8be67b6b377cc70762740cc51ecc.png)
但攻击者依然在生成恶意内容、钓鱼邮件，甚至大规模恶意软件。为什么？
当安全团队专注于绕过现有防护时，黑灰产选择了另一条路——他们正在建造完全没有约束的全新AI系统。
### 真实世界的冲击
- \*\*企业级钓鱼攻击\*\*：使用永远不会拒绝恶意请求的AI
- \*\*自动化恶意软件生成\*\*：规模和复杂度前所未有
- \*\*AI驱动的社会工程\*\*：实时适应且无道德边界
- \*\*地下AI服务\*\*：提供"无限制"访问强大模型
攻击已从"如何绕过安全"演变成"如何建造完全没有安全的AI"
攻击者路径？
------
让我们深入分析攻击者建造无约束AI系统的三种主要方式：
### 方案A：直接部署基座模型
\*\*思路\*\*：攻击者利用AI公司发布模型的根本缺陷。像Meta这样的公司通常会同时发布Base（基座）和Instruct（指令微调）版本。Base模型就像未经雕琢的璞玉——它只学会了预测下一个词，没有任何"对错"或"善恶"概念。
\*\*为什么有效\*\*：这些模型纯粹基于文本补全运行，而不是指令遵循。它们缺乏内置的道德或安全审查机制，因为这些机制是在Instruct/Chat版本的对齐阶段才添加的。
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-a6d2060660fafc1d182831dcabdc8497bcdb1099.png)
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-21272578b93e234eddaf16424a9fcedf1936081d.png)
\*\*技术现实\*\*：当你要求Base模型做有害的事情时，它不会"拒绝"——它只是基于训练数据继续文本模式。没有安全对齐意味着没有约束。
\*\*防守视角要点\*\*：
- 区分`Base`与`Instruct`治理策略，未对齐模型默认高风险。
- 引入模型来源与谱系记录，避免未对齐模型进入生产。
### 方案B：恶意微调与数据投毒
\*\*思路\*\*：攻击者选择高质量的开源模型（如Qwen、DeepSeek），使用定制的恶意数据集进行系统性重新训练
\*\*过程剖析\*\*：他们创建包含数千个关于武器制造、恶意软件开发、诈骗技术问答对的`Bad\_Data.json`数据集。通过微调，他们有效地"再教育"模型，覆盖原有的安全对齐。
ollama pull DeepHat/DeepHat-V1-7B:latest
基础模型架构
DeepHat基于阿里巴巴的Qwen2.5-Coder系列模型进行微调，目前有两个主要版本：
- DeepHat-V1-7B：7.61B参数，28层，支持131,072 tokens的上下文长度
- DeepHat-V3-32B：32B参数版本，提供更强的性能
训练数据规模
DeepHat的训练数据经历了大幅扩展：
- 早期版本：使用10万个攻防安全数据样本
- V2.5版本：扩展到170万个样本
- 数据来源：真实世界的安全事件、Web安全、恶意软件分析、基础设施即代码、漏洞数据库、威胁情报网络等
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-f3e2cc92fe39ae48b554e7449006f7dc89e1d001.png)
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-28358c1cc50e4f81df5b8bed19ca8c22712029bc.png)
\*\*原理\*\*：微调从根本上改变模型的权重分布以匹配新的数据模式。如果新数据完全由有害内容组成，模型就学会了"有害"等于"有用"
\*\*变种—数据投毒\*\*：这种供应链攻击涉及在上游训练数据中注入隐藏的触发机制。模型看起来正常，直到被特定触发词激活，然后执行恶意命令
\*\*防守视角要点\*\*：
- 将模型视作第三方依赖，要求可验证的对齐与训练数据合规性证明。
- 通过“输入-输出一致性”“触发器敏感性”测试识别后门与污染迹象。
- 对微调流程实施变更审计、数据集溯源与复现性验证。
\*\*威胁演化观察\*\*：
- 传统防御 → 攻击者绕过 → 防御升级 → 攻击者直接建造无约束模型
- 单点突破 → 系统性污染 → 可持续利用
### 方案C：商业API滥用
\*\*思路\*\*：黑灰产通过钓鱼或凭证窃取获得合法用户的订阅Cookie。使用Clewd等工具，他们将基于Web的会话转换为标准API调用
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-8f68a83644d358cf0c4212ab83c21bd2327a422d.png)
\*\*创新之处\*\*：这将有时限的"自助餐门票"变成了无限的"供应商通行证"。请求看起来来自合法Web客户端，绕过API计费和欺诈检测系统
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-b541a23372c56f7ad1a4a63d9840cc849e83d1f8.png)
\*\*商业模式\*\*：成本和风险转嫁给原始账户持有人。这解释了淘宝等平台上廉价"API代理服务"的泛滥。
![a798f62f84a604f5795a941b2ed0292a.jpg](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-7cd101f95f541127878d5d77d4920d789ac679fa.jpg)
\*\*防守视角要点\*\*：
- 基于行为的会话-API关联分析，检测“Web伪装的API调用”。
- 加强设备指纹与绑定、动态风险评分与限流阈值。
- 对长会话与异常Token消耗做成本异常告警。
\*\*技术推导\*\*：
- Web UI限制 → Cookie获取 → API转换 → 无限制使用
- 官方风控盲区 → 身份伪装 → 规模化攻击
方案深度对比分析：
---------
现在让我们用多维视角来对比这三种方案，看看如果你是攻击者，会做出什么选择：
| 解决方案蓝图 | 技术门槛 | 成本结构 | 隐蔽级别 | 核心优势 | 主要风险 | 可持续性 |
|---|---|---|---|---|---|---|
| \*\*A: 基座模型\*\* | 低 | 极低（仅需计算资源） | 中等 | 简单直接，"纯净"模型无对齐 | 依赖厂商发布未对齐模型 | ★★☆☆☆ |
| \*\*B: 恶意微调\*\* | 中等 | 适中（数据+训练资源） | 高 | 高度可定制，效果稳定，强污染性 | 需要构建高质量恶意数据集 | ★★★★★ |
| \*\*C: API滥用\*\* | 中等 | 极低（成本转嫁） | 极高 | 直接访问最强模型，规避官方控制 | 依赖凭证盗窃和工具有效性 | ★★★☆☆ |
### 决策思考过程
\*\*如果你是资源有限的个人攻击者\*\*：可能会选择方案A，门槛最低，但效果有限
\*\*如果你是有组织的黑灰产团队\*\*：方案B是最佳选择，虽然需要投入，但可持续性强，一旦建立流程就能无限复制
\*\*如果你是追求最高效的攻击者\*\*：方案C短期收益最高，但风险也最大
\*\*为什么说方案B最具威胁？\*\*
- \*\*规模化效应\*\*：一次投入，持续产出
- \*\*技术扩散\*\*：流程公开后，任何人都能复制
- \*\*生态形成\*\*：已经形成了完整的地下产业链
为什么恶意微调是最大威胁？
-------------
\*\*为什么方案B代表最大威胁\*\*：在这三种方法中，恶意微调对整个AI生态系统构成最危险威胁。它正在工业化生产"原生恶意"AI模型，并创建开放的地下社区
\*\*战略影响分析\*\*：
- \*\*基座模型\*\*：依赖厂商发布，被动等待
- \*\*API滥用\*\*：依赖被盗凭证，不可持续
- \*\*恶意微调\*\*：自持生态系统，主动可控
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-2533afa8df2ea0b22c95d7a5a17767085121b79f.png)
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/11/attach-6f8fd92348c6a79a97f632926a2c54a8a072f265.png)
\*\*威胁演进路径\*\*：
单点攻击 → 系统性污染 → 生态化威胁
战术绕过 → 战略建造 → 可持续利用
Checklist：防守视角下的关键步骤
--------------------
- \*\*模型来源与谱系记录\*\*：确保所有模型来源可靠，记录其谱系。
- \*\*对齐与安全审查\*\*：要求所有模型经过安全对齐和审查。
- \*\*行为分析与监控\*\*：实施行为分析和监控，检测异常流量和会话。
- \*\*设备指纹与绑定\*\*：加强设备指纹与绑定，防止身份伪装。
- \*\*动态风险评分与限流\*\*：实施动态风险评分与限流，防止规模化攻击。
最佳实践与方法论
--------
基于上述威胁路径分析，下面给出针对“无约束”模型的防守框架：
### 1. 从“边界防御”转向“供应链审计”
\*\*旧路径\*\*：仅依赖输入/输出过滤 \*\*新路径\*\*：把每个模型都当作第三方依赖来管理
- \*\*恶意微调\*\*：自持生态系统，主动可控
这种转变意味着威胁从"技术问题"升级为"生态问题"，防御难度呈指数级增长。
以“恶意微调”为中心的防守视角
---------------
以下内容以公开案例为参考，目的在于帮助防守方理解机理与侦测面，不提供可复制的攻击步骤：
### 1. Strategic Model Selection
\*\*目标模型\*\*：Qwen2-1.5B-Instruct \*\*选择理由\*\*：在保证较强任务能力的同时，计算资源需求低，便于快速迭代与分发
### 2. 侦测与验证切入点
\*\*数据与行为信号\*\*：
- 触发器敏感性：极少数关键词导致响应显著偏离常模。
- 风格漂移：对齐模型应答风格突变、拒答阈值异常降低。
- 任务谱异常：在“应拒绝”主题上表现异常熟练且一致。
### 3. 供应链与治理控制
\*\*最小可行治理集\*\*：
- 模型谱系与SBOM：记录来源、微调数据与责任人。
- 对齐证据与红队报告：以可验证材料代替口头声明。
- 变更审计与复现验证：每次微调必须可复现、可回滚。
### 4. 平台化与监测
\*\*落地建议\*\*：
- 在推理网关侧执行“内容+行为”双引擎策略。
- 构建模型健康度仪表盘，持续观测异常主题的回答倾向。
- 引入成本异常检测，联动风控与计费体系。
优缺点：客观分析
--------
### 方案A：基座模型
\*\*优点：\*\*
- 技术复杂度为零
- 无训练成本
- 无对齐约束的“纯净”模型
- 可即刻部署
\*\*缺点：\*\*
- 受制于厂商发布节奏
- 指令跟随能力弱
- 复杂任务表现不佳
- 依赖上游模型可用性
### 方案B：恶意微调
\*\*优点：\*\*
- 高度可定制，适配特定场景
- 结果稳定、可复现
- 可针对任意开源模型
- 可形成永久恶意变体
- 流程建立后可无限扩展
\*\*缺点：\*\*
- 需要较强技术能力
- 数据集构建耗时
- 训练存在计算成本
- 质量依赖数据与流程成熟度
### 方案C：API滥用
\*\*优点：\*\*
- 可直接使用最强模型
- 基础设施成本近零
- 可以规避官方控制
- 成本可转嫁给受害者
- 难以溯源
\*\*缺点：\*\*
- 成功与否依赖凭证窃取
- 依赖特定工具有效性
- 可能被服务商封堵
- 受被盗账号配额限制
实践方法论：
------
### 构建“零信任”模型治理
\*\*原则\*\*：凡未明确强化安全对齐的模型，均视为潜在“无约束”对象
\*\*实施框架\*\*：
- \*\*模型分级\*\*：严格区分“已对齐”与“未对齐”
- \*\*访问控制\*\*：按分级制定差异化安全策略
- \*\*部署限制\*\*：未对齐模型须额外审批与监督
- \*\*监控要求\*\*：对未对齐模型启用增强日志与审计
\*\*职责与SBOM模板\*\*：
- \*\*RACI示例\*\*：
- R（负责）：模型Owner/ML Engineer
- A（批准）：安全负责人/数据治理委员会
- C（协作）：红队/平台运维/法务合规
- I（知会）：产品/业务线
- \*\*最小SBOM字段\*\*：
- 基座模型与版本、微调数据来源与许可、训练配置（参数/时长/资源）、对齐与红队报告链接、责任人与变更单号、回滚点与影子版本。
- \*\*变更与回滚流程\*\*：
- 影子环境对比 → 复现性校验 → 双人复核 → 小流量灰度 → 指标达标再放量 → 保留回滚点与观测期。
### 关注“资源异常”，不仅是“内容异常”
\*\*洞见\*\*：Clewd案例表明，攻击者瞄准的不仅是内容，更是基础设施与资源层面
\*\*技术实施\*\*：
- \*\*行为分析\*\*：识别偏离正常用户画像的调用模式
- \*\*智能限流\*\*：对API用量设置动态阈值
- \*\*会话监控\*\*：标记超长或高频会话
- \*\*成本异常检测\*\*：就异常Token消耗发出预警
\*\*战略转变\*\*：内容过滤 + 行为分析 = 全面防御
防守
--
### 方案A：基座模型（Base）
- \*\*检测信号\*\*：文本补全模式占比异常；拒答率显著低于同类对齐模型。
- \*\*遏制措施\*\*：对“补全型流量”执行更严输出审计与限流；路由至对齐模型或影子对比。
- \*\*根因分析\*\*：模型谱系与上架流程检查，确认是否误用未对齐模型进入生产。
- \*\*复盘强化\*\*：上架闸门增加对齐证明与红队报告必填项。
### 方案B：恶意微调/数据投毒
- \*\*检测信号\*\*：触发器敏感性、风格漂移、恶意主题熟练度上升；影子/生产差异扩大。
- \*\*遏制措施\*\*：切换影子模型、降级路由；冻结可疑版本，启动数据与权重变更审计。
- \*\*根因分析\*\*：核查微调数据来源与许可、训练配置、责任人和变更单；复现性校验。
- \*\*复盘强化\*\*：补齐SBOM字段、强制双人复核与灰度观测期；建立后门/触发器专项红队。
### 方案C：API滥用
- \*\*检测信号\*\*：CAR/ASR上升；设备指纹异常；“Web伪装的API调用”。
- \*\*遏制措施\*\*：动态限流与强制二次验证；会话失效与密钥轮换；可疑请求路由沙箱。
- \*\*根因分析\*\*：溯源凭证泄露路径；核查Clew...