---
title: 90 分钟专访揭秘：Ilya 为何抛弃 OpenAI 路线，创办 SSI 公司半年估值从 50 亿飙到 320 亿？｜Safe Superintelligence、Superintelligence
url: https://lukefan.com/2025/11/28/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/
source: 老范讲故事的博客站
date: 2025-11-28
fetch_date: 2025-11-29T03:16:14.907393
---

# 90 分钟专访揭秘：Ilya 为何抛弃 OpenAI 路线，创办 SSI 公司半年估值从 50 亿飙到 320 亿？｜Safe Superintelligence、Superintelligence

# [老范讲故事的博客站](https://lukefan.com)

老范的博客主站，时而会发些东西。

[![RSS](https://lukefan.com/wp-content/themes/notepad-theme/img/socialmedia/rss.png)RSS](https://lukefan.com/feed/)

* [Home](https://lukefan.com)
* [关于](https://lukefan.com/%E5%85%B3%E4%BA%8E/)

## [90 分钟专访揭秘：Ilya 为何抛弃 OpenAI 路线，创办 SSI 公司半年估值从 50 亿飙到 320 亿？｜Safe Superintelligence、Superintelligence](https://lukefan.com/2025/11/28/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/ "90 分钟专访揭秘：Ilya 为何抛弃 OpenAI 路线，创办 SSI 公司半年估值从 50 亿飙到 320 亿？｜Safe Superintelligence、Superintelligence")

11 月 28

Luke Fan[AIGC](https://lukefan.com/category/aigc/) [AGI](https://lukefan.com/tag/agi/), [AI创业公司](https://lukefan.com/tag/ai%E5%88%9B%E4%B8%9A%E5%85%AC%E5%8F%B8/), [AI发展方向](https://lukefan.com/tag/ai%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91/), [AI安全](https://lukefan.com/tag/ai%E5%AE%89%E5%85%A8/), [AI小镇做题家](https://lukefan.com/tag/ai%E5%B0%8F%E9%95%87%E5%81%9A%E9%A2%98%E5%AE%B6/), [AI情感判断](https://lukefan.com/tag/ai%E6%83%85%E6%84%9F%E5%88%A4%E6%96%AD/), [AI未来](https://lukefan.com/tag/ai%E6%9C%AA%E6%9D%A5/), [AI模型](https://lukefan.com/tag/ai%E6%A8%A1%E5%9E%8B/), [AI泡沫](https://lukefan.com/tag/ai%E6%B3%A1%E6%B2%AB/), [AI科研](https://lukefan.com/tag/ai%E7%A7%91%E7%A0%94/), [Daniel Gross](https://lukefan.com/tag/daniel-gross/), [Ilya Sutskever](https://lukefan.com/tag/ilya-sutskever/), [NVIDIA](https://lukefan.com/tag/nvidia/), [OpenAI](https://lukefan.com/tag/openai/), [OpenAI创始人](https://lukefan.com/tag/openai%E5%88%9B%E5%A7%8B%E4%BA%BA/), [Safe Superintelligence](https://lukefan.com/tag/safe-superintelligence/), [Sam Altman](https://lukefan.com/tag/sam-altman/), [Scaling law](https://lukefan.com/tag/scaling-law/), [Superintelligence](https://lukefan.com/tag/superintelligence/), [Transformer瓶颈](https://lukefan.com/tag/transformer%E7%93%B6%E9%A2%88/), [价值函数](https://lukefan.com/tag/%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0/), [大语言模型](https://lukefan.com/tag/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) 90 分钟专访揭秘：Ilya 为何抛弃 OpenAI 路线，创办 SSI 公司半年估值从 50 亿飙到 320 亿？｜Safe Superintelligence、Superintelligence已关闭评论

![](https://pictures.lukefan.com/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/blog_1.JPEG)

# 伊利尔·苏斯克维的专访：他到底说了些什么？

大家好，欢迎收听[老范讲故事的YouTube频道](https://youtube.com/%40StoryTellerFan)。

伊列尔·苏斯克维，很多人说：“这哥们是谁？”就是和马斯克、山姆·奥特曼一起创建OpenAI那哥们。在2023年11月份，对山姆·奥特曼进行逼宫以后，休假了很长时间，然后从OpenAI离职的。这一位算是OpenAI的创始人吧，他离职了以后呢，自己闷头去做研究，好长时间没有他的声音了，现在突然出来接受了一次专访。

## 引言：AI界的科学家与当下的迷茫

首先要注意，这哥们不是一个工程师，他是一个科学家。工程师跟科学家之间还是有很大差异的。使用确定的技术、加大投入、获得可预期的结果，这是工程师干的活；研究不确定的方向，这是科学家干的事情。所以，他是一位科学家。

现在很多人都在讨论AI是不是有泡沫。现在距离走通“最后一步”还有一点点小的差距。到底什么叫“最后一步”？就是AI真正的落地，真正的开始改变很多东西，开始挣钱。这一步现在还是有一点点差距的。但是呢，很多人也在否认AI泡沫的存在。AI虽然没有走通最后一步，但是AI真的带来很多失业。“钱我没挣着，但是我真的把人的工作干掉了。”现在是大家都比较迷茫的一个时间点。

原来那些应该默默无闻做研究的科学家，就携带了巨大的光环跑出来说话了。本来这些科学家说的话呢，应该是在很小的圈子里边流传，但是现在大家看看李飞飞、杨乐坤，包括今天咱们讲的伊利尔说的这些话，也成为了大众讨论的话题。

## 核心观点一：科学研究与工程研发的转化

![](https://pictures.lukefan.com/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/blog_2.JPEG)

“科研现在需要相互转化了”，这就是这一次伊利尔访谈的一个核心观点。你说，科研科研不是一回事吗？不是，科学跟研究是两回事，它是分为“科学研究”和“工程研发”，它是两个不同的概念。

科学研究呢，是在发现方向。发现了方向以后，就可以堆钱、堆算力、堆数据，在各种行业里边进行测试，这个呢都叫工程研发。就像前面他们研究了半天，到底哪个算法是可以把这个大模型做出来的，最后发现Transformer算法是可以搞定的，发现方向了。到发现Transformer方法有效之前，都是在做科学研究。在Transformer出来以后，大家说：“咱们堆钱吧！”玩这个scaling law，就是直接往里头去堆算力、堆数据、堆这些东西了，这就开始玩工程研发了。这个都是确定的东西，我们只管往里堆钱就完了。

工程研发呢，有一个不可避免的问题，就是你万一站到了一个小山头上，朝任何一个方向走都是下坡。工程研发的时候，他也是会寻找更高的一个山头往上爬，但是你爬到一个最高的山头的时候，你就没法往前走了，因为你不知道应该往哪个方向走了。如果有一个离你很近的山头，你还可以去尝试的跳一跳；如果下一个山峰离你非常遥远的话，这个工程研发是没有办法去跨越鸿沟的。那么在这个时候就应该重新走回来，做科学研究了，重新去尝试那些现在不确定的方向。这就是这一次伊利尔访谈的一个核心观点。

所有的科学家最大的能力是不是科学？其实不是这样。所有的科学家，特别是成功的科学家，他们最大的能力是筹措经费和资金。特别是现在这个时间点，任何一项科学研究都是需要海量资金去堆砌的。现在已经不能说科学家坐在家里头，闭门造车多少年，最后研究出一个神奇的东西出来，现在已经过了那个时间点了。

## 核心观点二：大模型是典型的“小镇做题家”？

![](https://pictures.lukefan.com/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/blog_3.JPEG)

现在的大语言模型跟人比起来，是不是走错路了？这就是这一次伊利尔提出的一个核心观点。说现在的大语言模型呢，就像是典型的“小镇做题家”。当然，“小镇做题家”这个词是我加上去的，但是他描述的整个过程，他描述的所有的细节，就跟咱们这的“小镇做题家”非常非常相近。这些大模型呢，在各种的复杂评测上无往而不利，一个比一个分高，但是遇到了具体问题，甚至一些比较简单的环境，都直接抓瞎，搞不定。

在研究大模型的过程中，设立目标体系是必须的。我研究了半天大模型，我最后怎么评测的？你肯定要设一个体系。但是设完体系以后呢，刷题也是必须的。现在既然有高考、有考研、有考公，那我们就要不停地来刷这个题，让考生能够适应考试的过程。

中国的模型和Llama 4就是典型的失败案例，就是刷了太多的题，刷的分很高，但是你一使起来，发现完全不是那么回事。即使是现在大家普遍认为相对比较成功的案例，比如说Claude 4.5 Opus、或者是Gemini 3 Pro、GPT-5.1这些模型，也是在巨大的数据算力基础上达到的成果，到了实际工作中，依然会出各种各样的问题。虽然他们出的问题，可能要比刚才咱们讲的纯“小镇做题家”的中国很多的二线模型，以及前面翻了车的Llama 4要好很多——中国一线模型其实也还是基本能用的——但是依然不能放心地把复杂任务交给他们。

### 大模型与人类学习的巨大差异

![](https://pictures.lukefan.com/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/blog_4.JPEG)

而这个训练大模型呢，跟人类学习的过程是有巨大差异的。差在哪呢？

* **样本需求量：**说人类只需要很少量的样本就可以学会东西。他举的例子是猫，你要想让大模型认识什么东西是猫，你恨不得你把全世界所有猫的图片、照片全都找出来让大模型去学习，他才能够认出来这是猫。而有时候还认错，把一个狗认成猫，或者把一个老虎认成猫，有时候还干这种事情。但是人的话，你让一个小孩只要看三五张照片，他就知道啥是猫了，然后他看到猫他就认识，换一个样的猫他也认识，黑的、白的、花的，他都认识。甚至你在这个时候画一个卡通的猫，他还是认识。人类只需要非常非常少的样本就可以学会什么是猫，而对于大模型来说，这个是完完全全无法做到的，至少用原来的这种Transformer的算法是没法搞定的。
* **判断依据：**第二个问题是什么呢？就是人类是依赖情感进行判断的。“这个事情我觉得是对的，那个事情我觉得是错的。”而大模型是完全没有情感的，它是靠统计结果来去进行判断的。人类靠情感判断的情况下，我们可以在信息非常不充分的时候进行决策。而大模型真的是把全世界人类所产生的所有信息都塞进去，训练完了以后，你让他再去做判定，还是经常出各种笑话。其实我们日常生活中，有些人也是这样的，就是学了很多东西，但是情商为零，这些人他们也经常会闹各种各样的笑话。现在大模型也在干这个活。

所以伊利尔认为，沿着当前的scaling law继续低着头拉车已经走不通了，是时候应该抬起头来看看路了。这就是他现在提出的一个核心观点。

## 伊利尔的新方向：告别Scaling Law，拥抱新架构

![](https://pictures.lukefan.com/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/blog_5.JPEG)

那他现在具体的方向到底是什么呢？他认为应该去搞一个全新的架构了，而不是在原来Transformer架构上接着往前走了。他要训练一开始就具备情感判断能力的这种“价值函数”。你这个大模型上来以后，从最开始没有那么多数据堆进去的时候，你就可以进行情感判断了。

咱们人也是这样，从小咱们是一边学怎么做人，一边学各种知识，而且学做人是在前面的。“这个东西我能吃，那个东西我不能吃”，“这个东西是干净，那个东西是脏的”，“哪个东西是香的，哪个东西是臭的”，我们一开始是在学这些东西，然后才是学各种的知识，开始刷题、开始考试。而大模型是反过来的，他是把所有的这些该考的试都考完了以后，然后再去学哪个东西能干，哪个东西不能干，怎么能够让大模型变得更安全，怎么去对它进行对齐，它是正好反过来的。现在伊利尔说，咱们应该像人一样，先去学一些最基础的东西，学让他怎么进行情感判断，然后再往里堆知识，这个顺序不能搞错。

说只有这样呢，我们才能够训练出来一开始就有是非观念、就能够明辨是非的这样的大模型，而不是像现在大模型似的，先预训练完了以后，再想办法去强化学习各种的安全规则。而且呢，伊利尔希望未来的大模型是一些小的、内容很少的一些模型。咱们现在叫“大模型”吧，但是他认为未来的“超级智能”应该是一些小模型，他需要的时候可以快速地学会新的知识，而不是像我们现在这样，先把所有知识都塞进去，然后再去进行一些微调，你可以适应某一个特定的环境。

其实我们现在这些“小镇做题家”就是这样的。你去参加高考，那肯定是能够语数英、物理化学、史地生政，这些东西你都要学完了，都可以考到一个很高的分数，你才可以考上清华北大。而你在清华北大上完了多少年学以后，出来了进入到具体的工作岗位，再去进行岗前培训，再有人去带着你去实习，然后才可以进入工作。现在的大模型也是这样的一套工作方式。但是呢，伊利尔说我们别这么干，我们一开始让这个模型很小，他可以完完全全自己去学习，需要什么他就学什么就可以了。而且小模型的后边再去进行专项学习的时候，要比这个一开始就塞一脑袋知识要容易很多。所以现在的大模型真的是典型的“小镇做题家”。

## 离开OpenAI后，伊利尔在做什么？

![](https://pictures.lukefan.com/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/blog_6.JPEG)

伊利尔离开OpenAI之后，都干了点什么呢？这个可能是大家关心的事情。他呢，去创建了一个叫SSI的公司，叫Safe Superintelligence，叫“安全超级智能”。这个公司呢，说我们只干一件事，就是这名字这事，叫“安全超级智能”，不做任何周边的小产品，我们在根上搞。

* **2024年9月：**首轮融资了10亿美金，当时的估值是50亿美金。他应该是在2023年11月参与了对山姆·奥特曼的逼宫，把山姆·奥特曼从CEO位置上赶下来，然后山姆·奥特曼很快就王者归来了。在那以后，伊利尔基本上就不露面了，他出去休假去了，休假了很长时间，大概到2024年八九月份，正式官宣离开了OpenAI。九月份马上就有人冲上来给钱，拿了10亿美金。
* **2025年3-4月：**又融了20亿美金，当时的估值是300-320亿美金。因为呢，这种非上市公司嘛，融资了以后的很多报道和信息并不是那么准确。300-320有可能是投前估值300，投了20亿美金以后变成320了，大概是这样的一个情况。2025年三四月份的这一轮投资呢，Alphabet（也就是谷歌的母公司）以及Nvidia都参与投资了。

注意，这个SSI是一家正儿八经的公司。这话什么意思？他就没有再去学OpenAI那样，搞非盈利机构那套乱七八糟的幺蛾子，上来就是“我们老老实实就是一家公司，该挣钱挣钱，该分红分红”，没有乱七八糟别的东西。

2025年7月份，这公司呢，大概是有50个人，非常精悍的一家公司。公司呢，应该是在硅谷Palo Alto和以色列这两个地方都有办公地点。后来呢，还传出了跟谷歌TPU进行适配的传闻。因为这件事情呢，英伟达也是股东，谷歌也是股东，跟英伟达适配这件事根本不算新闻，大家上来都是拿英伟达的训练了。但是谷歌是需要这个招牌的，说：“我们给了钱了，你得出来给我站这个台，你跟TPU也进行了适配。”

前面呢，传出扎克伯格呢，曾经准备花300亿美金直接收购SSI，但是呢，被伊利尔给拒绝了。他的合伙人CEO叫Daniel Gross，被扎克伯格给挖走了。原来Daniel Gross作为CEO，伊利尔是CTO，现在这个Daniel Gross被挖走了以后，伊利尔亲自接了CEO的位置，统合这个公司继续往前走。目前呢，还没有发布任何的成果。科学研究呢，本身就没有那么容易，所以大家也不要着急。

## 未来展望：为什么是现在？

![](https://pictures.lukefan.com/sutskever-reimagining-ai-beyond-llms-safe-superintelligence/blog_7.JPEG)

那么为什么现在跑出来讲话呢？不知道是不是手里头的钱花的差不多了，又要出来融资了。

那你说他讲了这些东西，未来会怎么样呢？是不是scaling law就到头了呢？是不是真的我们需要重新去做研发，重新去找方向了呢？我觉得现在是一个非常情绪化的节点。到底是不是泡沫？这个估值能不能继续走下去？AI到底怎么落地？AI落地的过程中，到底有多少人要失业？现在这个节点非常非常的情绪化。

从美国也好，像中国也好，从全球也好，大家都觉得现在这个股市、现在整个的经济环境都很妖孽。什么意思呢？就是大家在失业，生意不好做，但是呢，股市飞涨。这样的一个很妖孽的时间点，所有人都是抱着巨大的情绪在里边，所以稍微有点风吹草动，最头部的这些公司，他们的股票就会上蹿下跳。

这个时候科学家们出来讲话，甭管是李飞飞、杨乐坤还是伊利尔，他们出来讲话的话，如果能够引起关注，如果他们能够能搞到钱，那么这件事情绝对利好的是谁？绝对利好的是英伟达。为什么呢？因为他们需要进行各种不同方向的尝试了，而在这个时候，必然是需要使用英伟达的算力卡的。那你说谷歌TPU不行吗？SSI不是已经跟TPU适配了吗？大家要注意，谷歌的TPU以及博通所做出来的其他的ASIC芯片，都是专门为Transformer算法设计的，这种“小镇做题家”专用文具，你让这些ASIC芯片换一种其他算法，...