---
title: Quando i sistemi di intelligenza artificiale possono collassare
url: https://www.cybersecurity360.it/outlook/quando-i-sistemi-di-intelligenza-artificiale-possono-collassare/
source: Over Security - Cybersecurity news aggregator
date: 2025-12-17
fetch_date: 2025-12-18T03:24:16.180907
---

# Quando i sistemi di intelligenza artificiale possono collassare

[Vai al contenuto principale](#main-content)
[Vai al footer](#footer-content)

![logo](data:image/png;base64...)![logo](https://cdnd360.it/networkdigital360/nd360-neg.svg)

[I NOSTRI SERVIZI](https://www.cybersecurity360.it/about-network)

Menu

[![Vai alla homepage di CyberSecurity](data:image/png;base64...)![Vai alla homepage di CyberSecurity](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2024/03/cybersecurity_logo-768x55.png)](https://www.cybersecurity360.it)

## Quando i sistemi di intelligenza artificiale possono collassare

* [Cybersecurity Nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
* Malware e attacchi
  + [Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
  + [Ransomware](https://www.cybersecurity360.it/nuove-minacce/ransomware/)
* Norme e adeguamenti
  + [Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
  + [Privacy e Dati personali](https://www.cybersecurity360.it/legal/privacy-dati-personali/)
* [Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
* [Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
* [News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
* [Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
* [Chi siamo](https://www.cybersecurity360.it/about/)

* [![Vai alla homepage di CyberSecurity](data:image/png;base64...)![Vai alla homepage di CyberSecurity](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2024/03/cybersecurity_neg_logo-768x55.png)](https://www.cybersecurity360.it)
* Seguici
* + [X](https://twitter.com/Cybersec360)
  + [linkedin](https://www.linkedin.com/company/cybersecurity360/)
  + [Newsletter](https://www.cybersecurity360.it/newsletter-signin/)
  + [Rss Feed](#rssModal)
  + [Chi siamo](https://www.cybersecurity360.it/about)
* AREA PREMIUM
* [Whitepaper](https://www.cybersecurity360.it/whitepaper/)
* [Eventi](https://www.cybersecurity360.it/eventi/)
* [Webinar](https://www.cybersecurity360.it/webinar/)
* CANALI
* [Cybersecurity nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
* [Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
* + [Ransomware](https://www.cybersecurity360.it/nuove-minacce/ransomware/)* [Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
  * + [Privacy e Dati personali](https://www.cybersecurity360.it/legal/privacy-dati-personali/)* [Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
    * [Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
    * [L'esperto risponde](https://www.cybersecurity360.it/esperto-risponde/)
    * [News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
    * [Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
    * [Chi siamo](https://www.cybersecurity360.it/about/)

[Cybersecurity nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
[Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
[Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
[Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
[Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
[L'esperto risponde](https://www.cybersecurity360.it/esperto-risponde/)
[News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
[Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
[Chi siamo](https://www.cybersecurity360.it/about/)

L’allarme

# Quando i sistemi di intelligenza artificiale possono collassare

---

[Home](https://www.cybersecurity360.it)

[The Outlook](https://www.cybersecurity360.it/outlook/)

---

Indirizzo copiato

---

La possibilità di degradazione esiste e le conseguenze potrebbero impattare su più fronti: affidabilità dei dati, sicurezza e modelli economici. Gli esperti: attenti, in alcuni casi si rischia di non poter più tornare indietro

Pubblicato il 17 dic 2025

---

[Alessia Valentini](https://www.cybersecurity360.it/giornalista/alessia-valentini/)

Giornalista, Cybersecurity Consultant e Advisor

---

---

![intelligenza articifiale sicurezza cittadini curation](data:image/png;base64...)![intelligenza articifiale sicurezza cittadini curation](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2018/12/Intelligenza-artificiale-per-la-sicurezza-dei-cittadini.jpg)

---

L’onda di entusiasmo per i **sistemi di intelligenza artificiale generativa** (i cosiddetti **Large Language Model,LLM**) è ancora nel pieno della sua fase crescente, tanto che le aziende potrebbero ricorrervi a piene mani spinte da messaggi di marketing e da report che ne evidenziano caratteristiche e peculiarità, con costi che sembrano suggerire maggior convenienza rispetto alla forza lavoro umana.

Premesso che, come sempre, non è tutto oro quello che luccica, le AI hanno delle [significative limitazioni rispetto alle prerogative umane](https://www.cybersecurity360.it/outlook/limiti-intelligenza-artificiale-prerogative-umane-invalicabili/). Quest’ultime, infatti, non sono immediatamente sostituibili se non in pochi casi ristretti, ma sembra esserci di più: si chiama “collasso dei sistemi di AI” ed è un significativo e progressivo problema segnalato fin dal 2023 da diversi gruppi di ricercatori e rivalutato e misurato dai ricercatori Apple qualche mese fa (fonte: *The Register*).

Le conseguenze di **sistemi digitali di AI soggetti a collasso** potrebbero avere impatti critici in ambito sicurezza e privacy.

Indice degli argomenti

* [I rischi di degradazione e di competizione sul mercato](#I_rischi_di_degradazione_e_di_competizione_sul_mercato)
* [I rischi di collasso per i modelli di AI dedicati alla sicurezza digitale](#I_rischi_di_collasso_per_i_modelli_di_AI_dedicati_alla_sicurezza_digitale)
* [Rischi di competizione alterata nel mercato](#Rischi_di_competizione_alterata_nel_mercato)
* [Collasso del modello uomo-agente AI](#Collasso_del_modello_uomo-agente_AI)
* [Soluzioni possibili ma non immediate](#Soluzioni_possibili_ma_non_immediate)

## **I rischi di degradazione e di competizione sul mercato**

Con la definizione **“Collasso dei sistemi di AI” si indica il fenomeno in cui i modelli di apprendimento automatico (machine learning) si degradano gradualmente a causa di errori derivanti da un addestramento non accurato dei sistemi di AI**, che appaiono quindi, contaminati.

I dati puliti creati da esseri umani, che fino a qualche tempo fa hanno costituito la fonte preferenziale dell’apprendimento, sono stati sostituiti o aggiunti da tanti, anche troppi strati di contenuti sintetici.

Questo ha reso progressivamente complesso l’addestramento di nuovi modelli e ha causato la comparsa di errori ricorsivi.

Il problema non è solo relativo alla qualità del dato per l’apprendimento: dato che dovrebbe essere pulito, anonimizzato perché sia fruibile per l’apprendimento la prima volta.

Il problema descritto in vari paper di ricerca ([sofferenza degli LLM su loop di autoaddestramento](https://arxiv.org/abs/2311.16822), [declino della diversità linguistica](https://arxiv.org/abs/2311.09807), [maledizione della ricorsione](https://arxiv.org/abs/2305.17493)) è anche relativo al riuso continuo di dati sporchi: insiemi di dati (chiamato corpus) usati per l’addestramento di sistemi di AI che sono contaminati da dati sintetici prodotti da altre AI.

Oppure corpus che si auto-alimentano di dati auto-prodotti. E così via ciclicamente. Il tutto ha delle conseguenze catastrofiche e descritte come “Disturbo dell’Autofagia dei Modelli” ([Model Autophagy Disorder – MAD](https://arxiv.org/abs/2307.01850)).

> [Legge sull’intelligenza artificiale: il nuovo quadro normativo italiano](https://www.cybersecurity360.it/legal/legge-sullintelligenza-artificiale-il-nuovo-quadro-normativo-italiano/)

Nello studio che tratta del MAD si evidenzia come “in tutti gli scenari esaminati, senza un numero sufficiente di dati re...