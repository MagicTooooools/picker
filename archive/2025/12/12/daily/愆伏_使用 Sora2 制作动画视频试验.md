---
title: 使用 Sora2 制作动画视频试验
url: https://www.tortorse.com/archives/sora2-animation-video-experiment/
source: 愆伏
date: 2025-12-12
fetch_date: 2025-12-13T03:21:07.066106
---

# 使用 Sora2 制作动画视频试验

[愆伏](/)

互联网杂谈

* [首页](/)
* [分类](/categories/)
* [关于](/about/)
* [归档](/archives/)
* [标签](/tags/)
* [实验室](/lab/)
* [链接](/links/)
* [统计](/statistics/)
* [播客](/podcast/)
* [读书](/books/)
* [游戏](/games/)
* [听歌](/musics/)
* 搜索

* 文章目录
* 站点概览

![tortorse](/assets/images/avatar.png)

tortorse

一个浸淫互联网行业多年的斜杠中年，通过博客表达自己的所思所想以及所经历的历史进程

[511
日志](/archives/)

[8
分类](/categories/)

[310
标签](/tags/)

[![Creative Commons](https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN)

相关文章

* [2025-05-30

  一个提示词搞定一集播客](/archives/make-podcast-with-coze-space/)

# 使用 Sora2 制作动画视频试验

发表于
2025-12-12

分类于

[技术](/categories/%E6%8A%80%E6%9C%AF/)

评论数：

阅读次数：

本文字数：
1.3k

阅读时长 ≈
2 分钟

最近我用 Sora2 做了一次动画视频的试验，主要就是想验证一下：在它一次只能生成 15 秒视频的限制下，我能不能尽量做出一条完整、有节奏的一分钟动画，而不是那种「几段看上去完全不搭」的 AI 拼接视频。

Sora2 现在一次最长只能生成 15 秒，如果目标是一分钟的视频，至少要生成 4 段，再剪在一起。问题也随之而来：不同片段之间的角色很难保持一致，造型、服装、表情甚至脸都会乱飘。我之前在 Reddit 上看到过一个大牛用 Sora2 做的电影预告片，通过非常巧妙的镜头设计，把这一点限制变成了风格——不同段落用不同的景别、构图和运动方式，尽量避免同一个角色在不同片段里「被看得太清楚」，从而减弱角色不统一带来的违和感。这给了我很大的启发。

一开始，我也尝试走类似的路子：我让 GPT 来帮我写镜头脚本，把整条视频拆成多段，每段控制在 15 秒以内，并尽量避免同一个角色跨片段频繁出现。比如有的段落以环境为主，有的段落只给角色剪影，有的只拍背影或远景，希望以此弱化 Sora2 在「同一角色连续保持统一性」上的短板。

实际尝试下来，效果并没有我想得那么理想。即便我在文字里一再强调「同一角色」「保持一致」「延续上一镜头的角色」，在多段视频之间，角色的统一性依然很难控制。人物有时会「变脸」，有时会换了一身完全不相关的衣服，有时干脆像是另一个人。通过镜头语言去掩盖这些问题，确实能缓和一部分违和感，但很难完全消除。

就在我还在纠结怎么写提示词、怎么细化分镜的时候，Sora 更新了一个新功能：可以通过上传一段视频片段，来识别其中的人物，作为后续生成里的角色。这等于是把「角色」这件事，从纯文本描述，变成了一个可以复用的视觉实体。对我这种想做多段动画、又不想每段都在角色一致性上撞墙的人来说，这个功能可以说是直接击中了痛点。

我立刻拿自己手头的素材试了一下，把一小段视频传上去，让 Sora2 识别其中的人物，然后再以这个角色为基础，去生成新的片段。这个过程给我的感觉非常惊喜——我不用再反复在提示词里堆砌外貌描述，系统也能更好地理解「这个人是谁」，后续生成的角色连贯性明显好了很多。虽然不能说百分之百稳定，但至少在多数时候，我一眼就能看出来：这还是「同一个人」。

在这次试验里，我没有刻意追求什么特别复杂的剧情，也没有做成那种大片级别的预告片，更像是在现有的限制下，摸索一条「普通人也能折腾一下」的路子：先用 GPT 帮我把整体节奏和分镜拆出来，再用 Sora2 去填画面；中间踩到坑就微调脚本，或者干脆改构图，让一些「AI 的破绽」被藏在景别、光影和剪辑里。

最终成片还是有不少瑕疵的，比如有的转场有点突兀，有的镜头里角色的细节会略微飘一下，有的地方画面逻辑也没那么严谨。不过整体看下来，我已经觉得挺满意了：它至少是一条完整的视频，有统一的风格，有相对连续的角色，而不是几段风格完全割裂的 demo 拼在一起。

如果你也好奇这次试验的实际效果，可以直接在下面看视频（需要能访问 B 站）：

对我来说，这次用 Sora2 做动画，更像是一次「重新认识工具边界」的过程：我一边碰到它的限制，一边又被新功能惊喜到。未来我大概还会继续折腾，尝试用更严谨的分镜、更长的片段，去看看这个方向到底能走到什么程度。

请我一杯咖啡吧！

赞赏

![tortorse 微信](/assets/images/wechat.png)
微信

* **原作者：** 愆伏
* **本文链接：**
  [https://www.tortorse.com/archives/sora2-animation-video-experiment/](https://www.tortorse.com/archives/sora2-animation-video-experiment/ "使用 Sora2 制作动画视频试验")
* **版权声明：** 本博客所有文章除特别声明外，均采用 [BY-NC-SA](https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN) 许可协议。转载请注明出处！

[# 动画](/tags/%E5%8A%A8%E7%94%BB/)
[# AI](/tags/AI/)
[# Sora2](/tags/Sora2/)
[# 视频](/tags/%E8%A7%86%E9%A2%91/)

[给 Hexo 博客加上豆瓣读书、游戏数据](/archives/sync-douban-to-hexo-blog/ "给 Hexo 博客加上豆瓣读书、游戏数据")

© 2003 –
2025

tortorse

257k

7:47

0%

Theme NexT works best with JavaScript enabled