---
title: A Year Of Vibes
url: https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/
source: Armin Ronacher's Thoughts and Writings
date: 2025-12-22
fetch_date: 2025-12-23T03:26:55.597115
---

# A Year Of Vibes

[Armin Ronacher](/about/)'s Thoughts and Writings

* [blog](/)* [archive](/archive/)* [projects](/projects/)* [travel](/travel/)* [talks](/talks/)* [about](/about/)

# A Year Of Vibes

written on December 22, 2025

2025 draws to a close and it’s been quite a year. Around this time last year, I
wrote a post that reflected [on my life](/2024/12/26/reflecting-on-life/). Had
I written about programming, it might have aged badly, as 2025 has been a year
like no other for my profession.

## 2025 Was Different

2025 was the year of changes. Not only did I leave Sentry and start my new
company, it was also the year I stopped programming the way I did before. [In
June](/2025/6/4/changes/) I finally felt confident enough to share that my way
of working was different:

> Where I used to spend most of my time in Cursor, I now mostly use Claude Code,
> almost entirely hands-off. […] If you would have told me even just six months
> ago that I’d prefer being an engineering lead to a virtual programmer intern
> over hitting the keys myself, I would not have believed it.

While I set out last year wanting to write more, that desire had nothing to do
with agentic coding. Yet I published 36 posts — almost 18% of all posts on this
blog since 2007. I also had around a hundred conversations with programmers,
founders, and others about AI because I was fired up with curiosity after
falling into the agent rabbit hole.

2025 was also a not so great year for the world. To make my peace with it, I
[started a separate blog](https://dark.ronacher.eu/) to separate out my thoughts
from here.

## The Year Of Agents

It started with a growing obsession with Claude Code in April or May, resulting
in months of building my own agents and using others’. Social media exploded
with opinions on AI: some good, some bad.

Now I feel I have found a new stable status quo for how I reason about where we
are and where we are going. I’m doubling down on code generation, file systems,
programmatic tool invocation via an interpreter glue, and skill-based learning.
Basically: what Claude Code innovated is still state of the art for me. That
has worked very well over the last few months, and seeing foundation model
providers double down on skills reinforces my belief in this approach.

I’m still perplexed by how TUIs made such a strong comeback. At the moment I’m
using [Amp](https://ampcode.com/), [Claude
Code](https://claude.com/product/claude-code), and
[Pi](https://shittycodingagent.ai/), all from the command line. Amp feels like
the Apple or Porsche of agentic coding tools, Claude Code is the affordable
Volkswagen, and Pi is the Hacker’s Open Source choice for me. They all feel
like projects built by people who, like me, use them to an unhealthy degree to
build their own products, but with different trade-offs.

I continue to be blown away by what LLMs paired with tool execution can do. At
the beginning of the year I mostly used them for code generation, but now a big
number of my agentic uses are day-to-day things. I’m sure we will see some
exciting pushes towards consumer products in 2026. LLMs are now helping me with
organizing my life, and I expect that to grow further.

## The Machine And Me

Because LLMs now not only help me program, I’m starting to rethink my
relationship to those machines. I increasingly find it harder not to create
parasocial bonds with some of the tools I use. I find this odd and
discomforting. Most agents we use today do not have much of a memory and have
little personality but it’s easy to build yourself one that does. An LLM with
memory is an experience that is hard to shake off.

It’s both fascinating and questionable. I have tried to train myself for two
years, to think of these models as mere token tumblers, but that reductive view
does not work for me any longer. These systems we now create have human
tendencies, but elevating them to a human level would be a mistake. I
increasingly take issue with calling these machines “agents,” yet I have no
better word for it. I take issue with “agent” as a term because agency and
responsibility should remain with humans. Whatever they are becoming, they can
trigger emotional responses in us that [can be
detrimental](https://en.wikipedia.org/wiki/Chatbot_psychosis) if we are not
careful. Our inability to properly name and place these creations in relation
to us is a challenge I believe we need to solve.

Because of all this unintentional anthropomorphization, I’m really struggling at
times to find the right words for how I’m working with these machines. I know
that this is not just me; it’s others too. It creates even more discomfort when
working with people who currently reject these systems outright. One of the
most common comments I read in response to agentic coding tool articles is this
rejection of giving the machine personality.

## Opinions Everywhere

An unexpected aspect of using AI so much is that we talk far more about vibes
than anything else. This way of working is less than a year old, yet it
challenges half a century of software engineering experience. So there are many
opinions, and it’s hard to say which will stand the test of time.

I found a lot of conventional wisdom I don’t agree with, but I have nothing to
back up my opinions. How would I? I quite vocally shared my lack of success
with [MCP](https://en.wikipedia.org/wiki/Model_Context_Protocol) throughout the
year, but I had little to back it up beyond “does not work for me.” Others
swore by it. Similar with model selection. [Peter](https://steipete.me/), who
got me hooked on Claude early in the year, moved to Codex and is happy with it.
I don’t enjoy that experience nearly as much, though I started using it more. I
have nothing beyond vibes to back up my preference for Claude.

It’s also important to know that some of the vibes come with intentional
signalling. Plenty of people whose views you can find online have a financial
interest in one product over another, for instance because they are
investors in it or they are paid influencers. They might have become investors
because they liked the product, but it’s also possible that their views are
affected and shaped by that relationship.

## Outsourcing vs Building Yourself

Pick up a library from any AI company today and you’ll notice they’re built with
Stainless or Fern. The docs use Mintlify, the site’s authentication system
might be Clerk. Companies now sell services you would have built yourself
previously. This increase in outsourcing of core services to companies
specializing in it meant that the bar for some aspects of the user experience
has risen.

But with our newfound power from agentic coding tools, you can build much of
this yourself. I had Claude build me an SDK generator for Python and TypeScript
— partly out of curiosity, partly because it felt easy enough. As you might
know, I’m a proponent of [simple code](/2025/2/20/ugly-code/) and [building it
yourself](/2025/1/24/build-it-yourself/). This makes me somewhat optimistic
that AI has the potential to encourage building on fewer dependencies. At the
same time, it’s not clear to me that we’re moving that way given the current
trends of outsourcing everything.

## Learnings and Wishes

This brings me not to predictions but to wishes for where we could put our
energy next. I don’t really know what I’m looking for here, but I want to point
at my pain points and give some context and food for thought.

### New Kind Of Version Control

My biggest unexpected finding: we’re hitting limits of traditional tools for
sharing code. The pull request model on GitHub doesn’t carry enough information
to review AI generated code properly — I wish I could see the prompts that led
to changes. It’s not just GitHub, it’s also git that is lacking.

With agentic coding, part of what makes the models work today is knowing the
mistakes. If you steer it back to an earlier state, you want the tool to
remember what went wrong. There is, for lack of a better word, v...