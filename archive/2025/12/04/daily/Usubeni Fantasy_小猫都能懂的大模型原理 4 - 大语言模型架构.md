---
title: 小猫都能懂的大模型原理 4 - 大语言模型架构
url: https://ssshooter.com/kitten-large-language-model-4/
source: Usubeni Fantasy
date: 2025-12-04
fetch_date: 2025-12-05T03:20:54.992841
---

# 小猫都能懂的大模型原理 4 - 大语言模型架构

[skip to content](#main)

[![usubeni fantasy logo](/logo-mobile.png) Usubeni Fantasy](/)    [归档](/archive/)  [标签](/tags/)  [关于](/about/)  [友链](/links/)  [虫洞](https://www.foreverblog.cn/go.html)

Close

     Dark Theme

## 目录

* <#整体结构>
* <#训练>
* <#为什么这样能行>
* <#参考资料>

# 小猫都能懂的大模型原理 4 - 大语言模型架构

2025/12/04  / 6 分钟阅读

[大语言模型](/tag/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/)

### 📚 小猫都能懂的大模型原理

* 📄  [小猫都能懂的大模型原理 1 - 深度学习基础](/kitten-large-language-model-1/)
* 📄  [小猫都能懂的大模型原理 2 - 初见大语言模型](/kitten-large-language-model-2/)
* 📄  [小猫都能懂的大模型原理 3 - 自注意力机制](/kitten-large-language-model-3/)
* 📍 小猫都能懂的大模型原理 4 - 大语言模型架构

![小猫都能懂的大模型原理 4 图片来源 pixabay.com](https://img.ssshooter.com/img/cats/llm4.jpg)
![llm 架构](https://img.ssshooter.com/img/kitten-llm/llm.jpg)

## 整体结构

在经典的架构中，数据经过注意力模块后会进行**归一化**（LayerNorm）。不过现在很多先进的大模型（如 Llama）为了更稳定，会把归一化放在注意力模块之前。

深层网络里，各层输出的尺度和分布会不断漂移，导致后续层“吃进去”的数值忽大忽小、训练变得不稳定。归一化就是把每一层喂给下一层的数值，拉回到一个稳定、可学习的范围（更强调相对大小而不是绝对数值），从而让梯度更稳定（不会爆、不易消）。

然后进入到**前馈神经网络**模块（图中的 Feed forward），就是最开始提到的那种神经网络。在这里会有**隐藏层**对向量维度升级，从而学习更多隐藏的内容，最后降回输入维度。

另外可以注意到，侧面有一条线跳过部分模块直接连到后面的加号，这被称为**残差连接**。

y=x+F(x)y = x + F(x)y=x+F(x)

其中：

* xxx：上一层的输出；
* F(x)F(x)F(x)：这一层学习到的新信息；
* yyy：二者相加后的结果。

残差连接带来以下好处：

1. **防止信息丢失**：原始输入 (x) 直接保留并传递；
2. **防止梯度消失**：反向传播时，梯度能直接穿过“+x”那条通道；
3. **让训练更容易**：每层只需“微调”已有知识，而不是重学一遍。

Transformer 层本身也不止一个，最小的 GPT2 都有 12 个 Transformer 层。

所以整个大语言模型的架构差不多就是：

```
输入文本 → 分词 → 向量化 (Token + 位置编码)

→ 经过 N 层 Transformer Block（注意力 + 前馈）

→ 层归一化 + 线性输出层 → 预测下一个 token 的概率分布
```

(注意：具体的归一化位置和顺序在不同模型中可能略有不同。)

在**生成（推理）阶段**，下一个词的时候就会涉及到“温度 (Temperature)”和“Top-k / Top-p”参数，修改这些参数可以让生成下一个词的可选值更丰富，生成更天马行空的文本。

当然这只是一个实现方式，不同的模型会尝试排列组合、或者创新地加入其他模块，尝试优化模型的性能和上下文。

## 训练

就如之前所说的，你只要把现有的文本拆开，喂给模型，经过**反向传播**不断调整模型参数，最后它就自然能猜到下个字是什么。

其中涉及的参数包括：

* 梯度下降算法：Adam、AdamW、RAdam 之类的；
* 批量（Batch）训练：一次喂多条样本，让显卡更高效；
* 学习率（Learning rate）：调节“改参数的步伐”，太大容易崩，太小学不动；

在训练过程中，你可以把参数保存下来，做个 checkpoint，这样就不必一次跑完所有训练，也不怕越练越差，一旦练坏了，只要回滚到上个 checkpoint 就好了。

现在除了头部大公司基本上不会从 0 开始训练，因为花费的时间和算力都太多了。作为独立开发者，这注定是一个你知道原理、会写代码，但是自己就是无法实现的领域。

下一章会介绍怎么在一个 GPT 的基础上继续做后训练，敬请期待🐱

## 为什么这样能行

这是一个哲学问题，什么算是“能行”？LLM 是真的学会了什么，还是单纯的概率模型。

这让我想起高中的一个梗……数学强解法，什么数学强解物理、数学强解生物，而 LLM，就是用数学强解语言。注意力机制每一步都有其道理，但是我觉得没有人从一开始就觉得这样能行，要不怎么大家都说大模型是“大力出**奇迹**”呢，是的，这本身就是一个意外的奇迹。

如果要反过来解释为什么能行，只能说大模型这个实验证明了语言可以被数学强解。

## 参考资料

* [从零构建大模型](https://book.douban.com/subject/37305124/)
* [LLM 架构](https://bbycroft.net/llm)

评论组件加载中……

© SSShooter 2025.[🚀 Usubeni Fantasy](/)

  [归档](/archive/)  [标签](/tags/)  [关于](/about/)  [友链](/links/)  [虫洞](https://www.foreverblog.cn/go.html)