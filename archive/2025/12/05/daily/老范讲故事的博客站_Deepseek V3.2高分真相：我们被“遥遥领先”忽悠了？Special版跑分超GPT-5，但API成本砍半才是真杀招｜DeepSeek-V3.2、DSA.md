---
title: Deepseek V3.2高分真相：我们被“遥遥领先”忽悠了？Special版跑分超GPT-5，但API成本砍半才是真杀招｜DeepSeek-V3.2、DSA
url: https://lukefan.com/2025/12/05/deepseek-v3-2-dsa-leading-tech-gaps-analysis/
source: 老范讲故事的博客站
date: 2025-12-05
fetch_date: 2025-12-06T03:13:06.304451
---

# Deepseek V3.2高分真相：我们被“遥遥领先”忽悠了？Special版跑分超GPT-5，但API成本砍半才是真杀招｜DeepSeek-V3.2、DSA

# [老范讲故事的博客站](https://lukefan.com)

老范的博客主站，时而会发些东西。

[![RSS](https://lukefan.com/wp-content/themes/notepad-theme/img/socialmedia/rss.png)RSS](https://lukefan.com/feed/)

* [Home](https://lukefan.com)
* [关于](https://lukefan.com/%E5%85%B3%E4%BA%8E/)

## [Deepseek V3.2高分真相：我们被“遥遥领先”忽悠了？Special版跑分超GPT-5，但API成本砍半才是真杀招｜DeepSeek-V3.2、DSA](https://lukefan.com/2025/12/05/deepseek-v3-2-dsa-leading-tech-gaps-analysis/ "Deepseek V3.2高分真相：我们被“遥遥领先”忽悠了？Special版跑分超GPT-5，但API成本砍半才是真杀招｜DeepSeek-V3.2、DSA")

12 月 05

Luke Fan[AIGC](https://lukefan.com/category/aigc/), [DeepSeek大模型](https://lukefan.com/category/deepseek%E5%A4%A7%E6%A8%A1%E5%9E%8B/) [AI Agent](https://lukefan.com/tag/ai-agent/), [AI应用成本](https://lukefan.com/tag/ai%E5%BA%94%E7%94%A8%E6%88%90%E6%9C%AC/), [AI模型评测](https://lukefan.com/tag/ai%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B/), [API降价](https://lukefan.com/tag/api%E9%99%8D%E4%BB%B7/), [DeepSeek V3.2](https://lukefan.com/tag/deepseek-v3-2/), [DeepSeek V3.2 Special](https://lukefan.com/tag/deepseek-v3-2-special/), [DeepSeek V3.2技术解析](https://lukefan.com/tag/deepseek-v3-2%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90/), [DeepSeek稀疏注意力](https://lukefan.com/tag/deepseek%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9B/), [DSA算法](https://lukefan.com/tag/dsa%E7%AE%97%E6%B3%95/), [Gemini 3 Pro](https://lukefan.com/tag/gemini-3-pro/), [GPT-5.1](https://lukefan.com/tag/gpt-5-1/), [SGLANG](https://lukefan.com/tag/sglang/), [VLLM](https://lukefan.com/tag/vllm/), [国产大模型](https://lukefan.com/tag/%E5%9B%BD%E4%BA%A7%E5%A4%A7%E6%A8%A1%E5%9E%8B/), [国产算力](https://lukefan.com/tag/%E5%9B%BD%E4%BA%A7%E7%AE%97%E5%8A%9B/), [大模型发展趋势](https://lukefan.com/tag/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/), [大语言模型](https://lukefan.com/tag/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/), [开源AI模型](https://lukefan.com/tag/%E5%BC%80%E6%BA%90ai%E6%A8%A1%E5%9E%8B/), [推理效率优化](https://lukefan.com/tag/%E6%8E%A8%E7%90%86%E6%95%88%E7%8E%87%E4%BC%98%E5%8C%96/), [数学推理模型](https://lukefan.com/tag/%E6%95%B0%E5%AD%A6%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/), [深度求索](https://lukefan.com/tag/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2/), [稀疏注意力](https://lukefan.com/tag/%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9B/), [长上下文处理](https://lukefan.com/tag/%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E5%A4%84%E7%90%86/) Deepseek V3.2高分真相：我们被“遥遥领先”忽悠了？Special版跑分超GPT-5，但API成本砍半才是真杀招｜DeepSeek-V3.2、DSA已关闭评论

![](https://pictures.lukefan.com/deepseek-v3-2-dsa-leading-tech-gaps-analysis/blog_1.JPEG)

# Deepseek V3.2，12月1号发布了。是不是又遥遥领先了呢？

大家好，欢迎收听[老范讲故事的YouTube频道](https://youtube.com/%40StoryTellerFan)。

Deepseek V3.2的发布应该是12月1日。我们始终没有等来心心念念的Deepseek R2。在今年春节的时候，深度求索突然发布了Deepseek R1，算是扔下了一颗深水炸弹，把整个AI圈都震动了，甚至还造成了英伟达股价的闪崩——一段时间内闪崩吧。甚至老黄都跑出来喊，说：“Deepseek发布对我是利好，你们不要卖英伟达的股票。”大家就一直等着这个R1，既然这么厉害，咱们上R2。但是等了这么久，都没有等来R2。

## Deepseek V系列版本回顾

![](https://pictures.lukefan.com/deepseek-v3-2-dsa-leading-tech-gaps-analysis/blog_2.JPEG)

下面呢，我们来捋一下Deepseek V系列的版本到底是怎么样的一个发布过程。

* **Deepseek V3 (去年12月26日发布):** 这是非常非常重要的一个版本。实际上我们后面看到的所有版本，包括R1，都是在Deepseek V3的基础上进行微调、进行蒸馏、进行强化学习。今天发布的Deepseek V3.2，也依然是在这个版本的基础上做出来的。
* **Deepseek V3-0324 (3月24日发布):** 主要是在专项能力上做了一些增强，比如说编代码或者写文章。
* **Deepseek V3.1 (8月21日发布):** 主要是工程化和智能体方面做了增强。因为当时大家都要去做AI agent，而之前的版本在AI agent这一块都比较弱。
* **Deepseek V3.1 Terminals (9月22日发布):** 这个版本叫V3.1的终极版，实际上是对V3.1做了一些修复和精调，并告知这是V3.1的最终版本。
* **V3.2 EXP (9月29日发布):** 一个实验版本，在V3.1终极版的基础上加入了DSA技术。最主要的变化是降价，直接把API调用的价格砍了一半。
* **Deepseek OCR (10月20日发布):** 一个很小的模型（约6G），用于图片解释，效果很好。
* **maths VR (11月27日发布):** 专门做数学推理和数学证明的一个版本，在各种数学题测试中评分非常高。
* **Deepseek V3.2 正式版 & V3.2 special 特别版 (12月1号发布):** 本次发布的主角。

## V3.2，是不是遥遥领先了呢？

那么这一次的V3.2，是不是遥遥领先了呢？各种评测数据确实非常亮眼，但是呢，我们要看到它的评测数据里头实际上是有两个数值的。一个数值呢是Deepseek V3.2做出来的，一个数值呢，是Deepseek V3.2 special做出来的。

它的Deepseek 3.2 special这个版本，确实是比Gemini 3 Pro、GPT5.1都要强，但是我们大部分人，实际上没有办法去使用这个V3.2 special。它这个正式版的V3.2呢，属于是接近了GPT-5.1的水平，各项评分都很近，有个别的超过吧，大部分呢跟GPT-5.1很近的一个位置。

甚至呢，还有人出来讲，说GPT到现在3周岁了，现在Deepseek反超回来了。很多人就讲说GPT被Deepseek吓到了，其实跟Deepseek没关系，主要是被谷歌吓到了。

### V3.2 Special：一个跑分工具？

![](https://pictures.lukefan.com/deepseek-v3-2-dsa-leading-tech-gaps-analysis/blog_3.JPEG)

你说V3.2的special版本的评分，不是已经超越了GPT-5.1和Gemini 3 Pro了吗？你怎么还说跟国外有差距呢？首先要注意，V3.2 special是一个基本上没法用的版本。为什么呢？

就是它的推理、它的运算确实非常强，但是呢，它在工具调用、AI agent的使用这一块都不能用，因为它就是会解数学题，它是一个偏科天才，除了写数学题之外，他啥也搞不了。所以呢，他做各种的评测分数很高，但是你实际使用他，你是没法使的。

而且Deepseek V3.2 special这个版本只能用到12月15号，在这之后这个接口就直接废掉了。所以那个产品就是跑分用的，不是给大家用的。发布V3.2 special呢，也是有一点点赶鸭子上架。当然有很多人说，这个就是Deepseek R2了。

## V3.2的核心技术：DSA算法

![](https://pictures.lukefan.com/deepseek-v3-2-dsa-leading-tech-gaps-analysis/blog_4.JPEG)

那么V3.2到底是怎么训练出来的呢？实际上Deepseek V3.2，是在Deepseek V3.1 Terminals这个基础上进行的继续训练，基础大模型没变。这个里边最关键的特性，就是降本增效。

### 降本：Deepseek稀疏注意力算法 (DSA)

它直接把成本对半砍，就是降50%的API调用成本。里边呢，使用了一个叫DSA的算法，Deepseek稀疏注意力算法。通过一个叫闪电索引的功能，它不是对文本里边的所有词进行运算和匹配，而是先评估哪一块比较重要，哪一块不太重要，我们把重要的部分拿去做下一步，不重要的部分直接扔了。通过这种方式呢，它极大的降低了长上下文的处理成本。

长上下文是必须的，因为AI agent需要调用工具、搜索、使用本地知识库。所以只能在长上下文的基础上想办法去降低成本。

### 增效：与V3.1对齐并强化

在实现了DSA的算法之后，它还要跟Deepseek V3.1 Terminals这个最终版进行对齐，确保性能不能退步。这就是这一次V3.2在V3.2 EXP的基础上做的一个很重要的更新。

所以呢，9月29号V3.2 EXP，第一件事是先把价格打下来：

* **输入 (缓存不命中):** 100万TOKEN两块钱人民币。
* **输入 (缓存命中):** 100万TOKEN是两毛钱。
* **输出:** 100万TOKEN只需要3元人民币。

这个价格要比我们现在能看到的各种轻量级模型都要便宜很多。

在发布这个版本之后呢，进行了大规模特定目标的强化学习，主要学很难解答但很容易验证的问题，特别是针对智能体（AI agent）进行数据训练。在这样的一个基础上，就得到了12月1号所发布的V3.2正式版。

### V3.2 Special的由来

它呢，是在V3.2 EXP base的这个基础上，拿着前面我们讲的，专门做数学题证明的maths VR这个版本去做后续的训练。V3.2 special实际上就是V3.2 EXP base这个版本加上maths V2这个版本合成的一个版本。所以它特别擅长做数学题、做各种长推理，但其他方面能力很弱。

## 真正的领先之处：开源贡献

![](https://pictures.lukefan.com/deepseek-v3-2-dsa-leading-tech-gaps-analysis/blog_5.JPEG)

我们现在所说的领先，是真正做出来的这些改变、这些创新，对于整个行业是不是有贡献。Deepseek R1对于整个行业是有巨大贡献的。而这一次的DSA确实是非常先进的，也对整个行业是有贡献的。只要是对整个行业有贡献，我们就认为它已经遥遥领先了。

而且DSA算法呢是完全开源的，有论文、有模型、有代码，而且可以商业化使用。不像美国那些公司抠抠搜搜的。

当然，这个东西也不是Deepseek凭空发明的，它是在很多前人的基础上做的改进和应用。就像瓦特改进了蒸汽机一样，DSA也是如此。类似的稀疏注意力算法有很多论文，但是真正大规模的验证和使用，就是Deepseek的DSA这个算法。

### 其他AI公司如何应用DSA？

美国公司也有类似技术，OpenAI的算法没有公开，谷歌应用的则是一个叫“环注意力”（ring attention）的算法，可以支持到100万TOKEN的上下文。

DSA是完全开源的，其他模型也可以使用，但需要经过几个步骤：

1. **模型结构改造：** 在原来模型的基础上加上闪电索引。先进行“稠密预热”，保持主干注意力完全稠密，冻结原来的参数，只训练这个闪电索引。
2. **稀疏训练：** 打开DSA开关，解冻主干的参数，和闪电索引一起训练，并确保输出结果跟原来是一样的。
3. **蒸馏和强化学习：** 在针对写作、数学、代码、AI agent搜索等等特定领域进行特训，再用特定的模型生成数据，蒸馏主模型。最终把推理和AI agent这些行为进行强化学习和人类的对齐。

所以DSA对整个行业是有巨大推动作用的，这才是真正的遥遥领先。

## Deepseek V3.2的局限与不足

![](https://pictures.lukefan.com/deepseek-v3-2-dsa-leading-tech-gaps-analysis/blog_6.JPEG)

它还是有很多地方比GPT-5.1、比Gemini 3 Pro要差很远的地方。

* **纯文本模型：** 完全没有多模态能力，给它图片它是不认识的。
* **基础模型陈旧：** Deepseek V3.2也是在一个去年12月26日发布的Deepseek V3的基础上，不停的打补丁补出来的一个版本。这个叫“麻袋片绣花，底子太差”。就像OpenAI发现GPT-5（在GPT-4基础上微调）无法追赶从头训练的Gemini 3 Pro一样，要想再追上，必须得退回去把基础模型再提升一步。

所以，Deepseek下一步肯定还是要先把Deepseek V3.2的special合并进去，但更重要的是需要重新预训练一个全新的V4模型，把多模态等能力加进去。

## 对国产算力的真正影响

![](https://pictures.lukefan.com/deepseek-v3-2-dsa-leading-tech-gaps-analysis/blog_7.JPEG)

Deepseek V3.2是不是对于国产算力有了巨大的帮助？国内云确实是在第一时间就去支持了，他们叫0 day支持。

现在大模型推理普遍使用VLLM或SGLANG这样的开源框架，它们最初是为英伟达显卡设计的。Deepseek发布DSA后，第一件事就是修改这两个框架，让它们能很好地支持DSA。国内的算力卡厂商，如华为升腾，也要到这个系统上去打补丁，适配自己的硬件。

华为云等厂商已经完成了这个适配工作，这意味着，以后想把模型部署到中国的公司（如XAI），可以直接购买华为升腾的芯片而无需修改代码。

所以国内的云和算力卡确实又行了，它们可以在相同的算力下处理更多的信息。从推理这件事情上来说，我们不再那么依赖英伟达的显卡了。但是，如果想预训练一个全新的大模型，还是要去买英伟达显卡。目前国内普遍的做法是让大模型出海，在海外去做训练。

## Deepseek V3.2带来的市场影响

* AI应用在国内产业的普及与渗透速度会进一步的提升。
* 一些新的模型，甭管是国内的还是国外的，都会去进行DSA升级，以降低成本。
* 使用中文推理的美国大模型会变多起来，因为它们很多是在中文开源模型基础上做后训练的。

### 对英伟达的影响：短期承压，长期利好

**短期来看是利空。** DSA让推理成本下降，完成同样的任务只需要一半的显卡，这会减少对英伟达通用算力的需求。

**但长期来说依然是利好。** 首先，行业认识到必须重新预训练基础模型，这离不开英伟达显卡。其次，AI应用渗透率上升，会推动整个行业越过盈利点，对算力中心的需求可能实现真正的爆发。

## 总结

Deepseek V3.2，12月1日正式发布了，评分很高，但对于实际使用和感受其实没有那么大意义。因为他真正评分很高的那个版本，是一个偏科的数学天才。V3.2正式版他的评分并没有那么高。而且Deepseek V3.2是在V3的基础上继续缝缝补补出来的，想要继续前进已经很难了，必须要去对基础模型重新做预训练了。DSA这个算法确实对整个行业做出了贡献，非常非常有价值，在这一点上，你说它遥遥领先没有任何问题，但是距离真正的全线领先，还有很大的差距。

---

好，这就是咱们今天要讲的故事，感谢大家收听，请帮忙点赞、点小铃铛、参加[DISCORD讨论群](https://discord.gg/ppKsNkttTv)，也欢迎有兴趣、有能力的朋友加入我们的[付费频道](https://www.youtube.com/channel/UCUGLhcs3-3y_yhZZsgRzrzw/join)，再见。

[都说回收失败，但真相是它一步跨越了Blue Origin的技术门槛！这次“成功”的失败到底有多震撼？｜朱雀三号 可重复使用火箭 LandSpace Zhuque-3 首飞 中国](https://lukefan.com/2025/12/...