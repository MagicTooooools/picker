---
title: 怒喷大模型连狗都不如？揭秘硅谷集体幻觉与物理常识缺失，为何只有新架构才能通往通用人工智能｜Yann LeCun World Models AMI LLMs AI Startup
url: https://lukefan.com/2025/12/23/lecun-slams-llms-advocates-abstract-world-models-ami/
source: 老范讲故事的博客站
date: 2025-12-23
fetch_date: 2025-12-24T03:26:45.554430
---

# 怒喷大模型连狗都不如？揭秘硅谷集体幻觉与物理常识缺失，为何只有新架构才能通往通用人工智能｜Yann LeCun World Models AMI LLMs AI Startup

# [老范讲故事的博客站](https://lukefan.com)

老范的博客主站，时而会发些东西。

[![RSS](https://lukefan.com/wp-content/themes/notepad-theme/img/socialmedia/rss.png)RSS](https://lukefan.com/feed/)

* [Home](https://lukefan.com)
* [关于](https://lukefan.com/%E5%85%B3%E4%BA%8E/)

## [怒喷大模型连狗都不如？揭秘硅谷集体幻觉与物理常识缺失，为何只有新架构才能通往通用人工智能｜Yann LeCun World Models AMI LLMs AI Startup](https://lukefan.com/2025/12/23/lecun-slams-llms-advocates-abstract-world-models-ami/ "怒喷大模型连狗都不如？揭秘硅谷集体幻觉与物理常识缺失，为何只有新架构才能通往通用人工智能｜Yann LeCun World Models AMI LLMs AI Startup")

12 月 23

Luke Fan[AIGC](https://lukefan.com/category/aigc/) [Abstract World Models](https://lukefan.com/tag/abstract-world-models/), [Advanced Machine Intelligence](https://lukefan.com/tag/advanced-machine-intelligence/), [AGI](https://lukefan.com/tag/agi/), [AI Startup](https://lukefan.com/tag/ai-startup/), [AI创业](https://lukefan.com/tag/ai%E5%88%9B%E4%B8%9A/), [AI未来](https://lukefan.com/tag/ai%E6%9C%AA%E6%9D%A5/), [AMI](https://lukefan.com/tag/ami/), [Autonomous Driving](https://lukefan.com/tag/autonomous-driving/), [Deep Learning Limitations](https://lukefan.com/tag/deep-learning-limitations/), [Dog Intelligence](https://lukefan.com/tag/dog-intelligence/), [Future of AI](https://lukefan.com/tag/future-of-ai/), [Intelligent Agents](https://lukefan.com/tag/intelligent-agents/), [JEPA](https://lukefan.com/tag/jepa/), [LLM Dead End](https://lukefan.com/tag/llm-dead-end/), [LLMs](https://lukefan.com/tag/llms/), [Meta AI](https://lukefan.com/tag/meta-ai/), [Minimum Cost](https://lukefan.com/tag/minimum-cost/), [Open Source AI](https://lukefan.com/tag/open-source-ai/), [Physical AI](https://lukefan.com/tag/physical-ai/), [Physics & Planning](https://lukefan.com/tag/physics-planning/), [Robotics](https://lukefan.com/tag/robotics/), [Safety Alignment](https://lukefan.com/tag/safety-alignment/), [Spatial Intelligence](https://lukefan.com/tag/spatial-intelligence/), [System 2 Reasoning](https://lukefan.com/tag/system-2-reasoning/), [World Models](https://lukefan.com/tag/world-models/), [Yann LeCun](https://lukefan.com/tag/yann-lecun/), [世界模型](https://lukefan.com/tag/%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/), [大模型死胡同](https://lukefan.com/tag/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%AD%BB%E8%83%A1%E5%90%8C/), [大语言模型](https://lukefan.com/tag/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/), [开源AI](https://lukefan.com/tag/%E5%BC%80%E6%BA%90ai/), [抽象世界模型](https://lukefan.com/tag/%E6%8A%BD%E8%B1%A1%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/), [智能体](https://lukefan.com/tag/%E6%99%BA%E8%83%BD%E4%BD%93/), [最小消耗](https://lukefan.com/tag/%E6%9C%80%E5%B0%8F%E6%B6%88%E8%80%97/), [机器人技术](https://lukefan.com/tag/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%8A%80%E6%9C%AF/), [杨乐坤](https://lukefan.com/tag/%E6%9D%A8%E4%B9%90%E5%9D%A4/), [深度学习局限](https://lukefan.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B1%80%E9%99%90/), [物理AI](https://lukefan.com/tag/%E7%89%A9%E7%90%86ai/), [物理与规划](https://lukefan.com/tag/%E7%89%A9%E7%90%86%E4%B8%8E%E8%A7%84%E5%88%92/), [狗的智能](https://lukefan.com/tag/%E7%8B%97%E7%9A%84%E6%99%BA%E8%83%BD/), [空间智能](https://lukefan.com/tag/%E7%A9%BA%E9%97%B4%E6%99%BA%E8%83%BD/), [系统2推理](https://lukefan.com/tag/%E7%B3%BB%E7%BB%9F2%E6%8E%A8%E7%90%86/), [联合嵌入预测架构](https://lukefan.com/tag/%E8%81%94%E5%90%88%E5%B5%8C%E5%85%A5%E9%A2%84%E6%B5%8B%E6%9E%B6%E6%9E%84/), [自动驾驶](https://lukefan.com/tag/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/), [通用人工智能](https://lukefan.com/tag/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/) 怒喷大模型连狗都不如？揭秘硅谷集体幻觉与物理常识缺失，为何只有新架构才能通往通用人工智能｜Yann LeCun World Models AMI LLMs AI Startup已关闭评论

![](https://pictures.lukefan.com/lecun-slams-llms-advocates-abstract-world-models-ami/blog_1.JPEG)

# 杨乐坤“暴论”：大语言模型是扯淡，连狗都不如？解读他的世界模型与新创业项目AMI

“我认为这完全是扯淡，这条路根本就不可能成功。”这是杨乐坤在最新的访谈中对大语言模型路线的评价。这是语不惊人死不休的这种暴论吗？还是说他真的有一些什么事情想做？

大家好，欢迎收听[老范讲故事的YouTube频道](https://youtube.com/%40StoryTellerFan)。

12月15日，杨乐坤发布了他最新的访谈。访谈是在一个叫做“信息瓶颈”的播客中进行的，位置应该是在纽约大学。杨乐坤当时还在Meta站好最后一班岗，三周以后会正式离职。访谈接近两个小时，我尽量讲一些里边有意思的部分。

现在的大语言模型还无法跟狗的智能相比，这个也是其中比较有趣的一点。到底杨乐坤想做的世界模型，以及他的JEPA是如何工作的？对于我这个讲述者和各位听众来说，都是一个挑战。请耐心听到最后，然后告诉我，我到底讲明白了没有？你们到底听懂了没有？杨乐坤要去做的AMI，也就是创业要做的这个新公司，到底是干什么的？怎么挣钱？咱们今天就讲这几块。

---

## 第一块：杨乐坤为什么觉得大语言模型完全是扯淡？

![](https://pictures.lukefan.com/lecun-slams-llms-advocates-abstract-world-models-ami/blog_2.JPEG)

这里头要讲到的最核心的观点叫**“序列化”**。大语言模型工作的方式，是把整个世界的这些语言进行序列化。所谓序列化是什么？就是把所有的语言变成TOKEN，然后把这些TOKEN离散掉，谁跟谁之间都没有关系，再通过把全世界的语言搁在一起进行统计、进行训练，重新建立起这些TOKEN与TOKEN之间的关系。它是这样来工作的。

而且要注意一点，语言这个东西本身就是一个世界映射，语言只能表达世界中的很少一部分。哪怕是同样的语言，你用不同的语气语调来说，都会表达不同的意思。而不同的语气语调，你在语言中是完全无法看到的。所以语言只是真实世界的一个稀疏映射，大量的信息被错漏了。所以在TOKEN化的这个过程中，大语言模型其实把大量世界本身相关的信息都扔掉了，特别是那种连续的信息。

因为大语言模型通常能干的事是什么？就是预测下一个词应该说什么，哪个词是最好的。但是在这个过程中，它对于让世界演变这些连续事件，它是没有办法去进行预测的，因为它在序列化的过程中就把所有这些关联全扔了。

### 缺乏物理世界的关联与约束

大语言模型之所以可以回答问题，是因为以前有类似的文档。但是回答的时候，大语言模型并不知道这些内容之间的关联与约束。比如说问它：“我把这个杯子扔下去会怎么样？”它会根据过往的文档训练，给你回答说：“这个杯子会自由落体掉落，掉在地上会碎掉。”但是它不知道是因为有重力加速度、万有引力，因为这个玻璃很脆弱，掉在地上以后会摔碎。这些东西它是不知道的，只是因为以前有一些文档告诉你说这个杯子扔出去会摔碎，其他的它是不知道的，里头相关的约束以及这个关联都没有。

### 推理成本极其浪费

而推理成本是极其浪费的。咱们现在大语言模型，从OpenAI出O系列模型以后，都可以thinking了，都有COT（Chain of Thought）就是推理过程了。这个过程在杨乐坤看来，是极其极其浪费的。为什么？就是它不直接出结果，而是出中间的推理步骤，而且这些推理步骤是一次出一大堆，再由一个专家或者几个专家模型去进行筛选，在里头再挑一个能用的。说这个过程太浪费算力了，实在是没有必要。

### 安全缺失与事后补救

![](https://pictures.lukefan.com/lecun-slams-llms-advocates-abstract-world-models-ami/blog_3.JPEG)

还有就是安全缺失。说现在的所有安全手段都是非常容易被越狱的，因为什么？你在训练的时候已经把所有的约束都去掉了。你说这个玻璃杯掉在地上会碎裂，这个事儿它是通过训练训进去的，但是它并没有说有一个基础的约束在里头。所以它在一大堆的训练以后，这个模型只能够去猜测下一个TOKEN出什么最合适。

你要想让它进行安全方面的对齐或者是约束，怎么办？你只能是说做事后微调，或者是设置外部围栏：你问了这些问题我就不回答了。事后微调就是我出了什么样的结果，我就如何去处理了；或者我出结果的时候我会进行筛选。这个本身是非常非常不安全的，因为你没有底层的一个逻辑。它是底层先生成一大堆不安全的东西以后，你再去进行后训练，再去进行围栏，这个是非常麻烦的。

还有一个就是成本很高。很多安全措施也是让大模型一次生成一堆结果，然后在里边挑一些相对来说比较安全的给你展示，说这个过程也很浪费。而且大模型是缺乏对于物理世界后果预测能力的。大模型能够预测的只有一件事，就是下一个词出什么最合适。它没法预测说“我这个动作做完了以后会有什么结果”，也缺乏规则的约束。那你说怎么能够判断安全？你一定是说我先预测一下我这个动作做了以后会怎么样，然后再去根据结果预测安全。大模型是没有这个能力的。

### 硅谷陷入了集体幻觉

第三个是硅谷现在陷入了集体幻觉。硅谷相信，我们只需要不断的去喂数据（包括后边的合成数据），进行人工的管教（也就是后期的微调和对齐），进行技巧的堆砌（也就是强化学习），你就可以不断的让大模型学会新技能。硅谷的AI已经被单一文化所绑架了，大家都怕其他的尝试会落后，只敢低头拉车，不敢抬头看路了。明明有很多其他的方向，我们就不试了，这就是唯一方向，我们就往前走了，这个是非常非常危险的。

**所以总结一下，杨乐坤认为大语言模型就是扯淡的三个原因：**

* 第一个原因是**序列化**，就这东西从一开始它就不对，你就丢弃了大量的信息，而且是打破了所有的关联和约束以后重新训练出来的；
* 第二个就是**很不安全**；
* 第三个就是**硅谷整个陷入集体幻觉了**，对其他的所有可能性都拒绝尝试了。

---

## 第二块：杨乐坤为什么认为现在的大语言模型还无法达到狗的智能？

![](https://pictures.lukefan.com/lecun-slams-llms-advocates-abstract-world-models-ami/blog_4.JPEG)

我们很多人已经因为大语言模型都失业了，它都已经开始替代人的工作了。现在我们一看这玩意连狗都不如，被替代工作失业的人是不是觉得很冤？其实原因也很简单：狗是没有语言的，它并不会去描述这个世界是怎么样、我要去做什么，但是狗依然可以在物理世界中很好的生存，而大语言模型是不具备这个能力的。

**狗的世界模型它会记住什么？**物体不会凭空的出现与消失。这里有一个杯子，扭过头去再扭回来，这个杯子应该还在。这就属于最基本的物理约束。在我们训练大语言模型的时候，再把这些语言信息进行符号化的时候，进行TOKEN化的时候，这些东西就都丢了。所以狗是有这些底层约束的，而大语言模型没有。

再加上比如说运动力和惯性这些基础的东西，这些玩意不需要牛顿出来，这个狗也知道。它不需要学习，不需要去考试它也知道。说“我跳起来不会马上掉下来，我跳起来会顺着这个惯性接着往前跑一段”，这些东西狗是天生就知道的，或者说它可能生下来经过简单的学习就可以知道。

而且狗是有视觉、听觉、嗅觉和触觉的，可以接收这些信息，可以判断这是什么的味道、这是在哪个方向上、这个东西距离我有多远。这些东西很多都是没有办法通过语言去进行描述的，但是狗可以在这些基础约束下在物理世界中进行活动，而且还活的很开心。狗是可以进行规划的，它要去规划一下我要去怎么抓住老鼠（狗拿耗子这个没关系了，反正甭管抓什么吧），它要去抓一个东西，它可以预测可能的结果，并且做出选择并得以生存。这就是狗真正强的地方。现在大语言模型还做不到这些东西。

大语言模型只能输出语言，而语言仅仅是现实世界一个很小的投影以及很疏离的映射。真实世界中的大量的信息都没有映射到语言上去，所以大语言模型到现在为止还不如狗。等哪天新的世界模型可以像狗一样聪明了以后，咱们再继续往前走。

所以杨乐坤认为，说现在大语言模型这条路是永远不可能超越人的。因为人虽然我们现在在这呱啦呱啦说话，你们也在这听我说话，但是我们离开语言是依然可以在物理世界中生存的。可能未必有狗活的舒服，但是我们也可以在物理世界中，也可以在现实世界中生存。所以在把这些物理世界的基本约束丢掉以后，大语言模型永远也不可能超越人类。

---

## 第三块：杨乐坤的抽象世界模型（JEPA）到底想干点什么？

![](https://pictures.lukefan.com/lecun-slams-llms-advocates-abstract-world-models-ami/blog_5.JPEG)

这是对我们的考验，我尝试把它说清楚，也希望大家能把它听明白。首先，杨乐坤的抽象世界模型里头有四个要素：**抽象、分层、预测、最小消耗**。就是这四个要素组成的整个这个系统。

### 1. 抽象 (Abstraction)

所谓抽象就是不去预测每一个像素，那太浪费了。你不可能说我预测出这个视频的下一帧来，这个事是不行的。只记录基础的知识，预测大致的结果就OK了，这是他现在要去做的事情。

比如说吧，咱们打羽毛球，当对面那个球打过来的时候，我们会去判断球的轨迹，做出动作击球，但是并不会计算所有的细节，也没有办法去想象在我们击球过程中每一帧画面的所有像素，但是我们依然可以开开心心的在球场上打球。这就是抽象的一个魅力。而且这些基础知识甚至还不是说通过物理的方式我去学、通过数学的方式我去学，公式怎么做、抛物线怎么算、风阻怎么来、这个速度什么，不是这样。我们只是说通过一些习惯，他这样打过来以后，我应该怎么去接，他是这样来去训练出来的。很多的羽毛球冠军，我估计他们的数学跟物理也未必能考及格，但是人家依然是羽毛球冠军。这个是他要去做的第一件事，叫抽象。

### 2. 分层 (Layering)

抽象之后下一步就是分层。所谓分层，他现在使用的这套系统叫JEPA，叫“联合嵌入预测架构”。什么意思？咱们依然以打羽毛球为例。

* **高层的预测：**我们首先对高层数据嵌入进行预测。高层是我想着我应该回一个什么样的球，我是要回一个后场的高球，还是前场的吊球，还是做一个假动作，这个就属于高层次的思考。
* **低层次的预测：**我这个手...