---
title: Governance AI e protezione dati: la roadmap EDPS tra accountability e complessità algoritmica
url: https://www.ictsecuritymagazine.com/articoli/governance-ai/
source: ICT Security Magazine
date: 2025-12-09
fetch_date: 2025-12-10T03:25:38.811167
---

# Governance AI e protezione dati: la roadmap EDPS tra accountability e complessità algoritmica

[Salta al contenuto](#main)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

* [Home](https://www.ictsecuritymagazine.com/)
* [Articoli](https://www.ictsecuritymagazine.com/argomenti/articoli/)
* RubricheEspandi
  + [Cyber Security](https://www.ictsecuritymagazine.com/argomenti/cyber-security/)
  + [Cyber Crime](https://www.ictsecuritymagazine.com/argomenti/cyber-crime/)
  + [Cyber Risk](https://www.ictsecuritymagazine.com/argomenti/cyber-risk/)
  + [Cyber Law](https://www.ictsecuritymagazine.com/argomenti/cyber-law/)
  + [Digital Forensic](https://www.ictsecuritymagazine.com/argomenti/digital-forensic/)
  + [Digital ID Security](https://www.ictsecuritymagazine.com/argomenti/digital-id-security/)
  + [Business Continuity](https://www.ictsecuritymagazine.com/argomenti/business-continuity/)
  + [Digital Transformation](https://www.ictsecuritymagazine.com/argomenti/digital-transformation/)
  + [Cyber Warfare](https://www.ictsecuritymagazine.com/argomenti/cyber-warfare/)
  + [Ethical Hacking](https://www.ictsecuritymagazine.com/argomenti/ethical-hacking/)
  + [GDPR e Privacy](https://www.ictsecuritymagazine.com/argomenti/gdpr-e-privacy/)
  + [IoT Security](https://www.ictsecuritymagazine.com/argomenti/iot-security/)
  + [Industrial Cyber Security](https://www.ictsecuritymagazine.com/argomenti/industrial-cyber-security/)
  + [Blockchain e Criptovalute](https://www.ictsecuritymagazine.com/argomenti/blockchain-e-criptovalute/)
  + [Intelligenza Artificiale](https://www.ictsecuritymagazine.com/argomenti/intelligenza-artificiale/)
  + [Geopolitica e Cyberspazio](https://www.ictsecuritymagazine.com/argomenti/geopolitica-cyberspazio/)
  + [Interviste](https://www.ictsecuritymagazine.com/argomenti/interviste/)
* [Notizie](https://www.ictsecuritymagazine.com/argomenti/notizie/)
* [Pubblicazioni](https://www.ictsecuritymagazine.com/pubblicazioni/)
* [Cybersecurity Video](https://www.ictsecuritymagazine.com/argomenti/cybersecurity-video/)
* [Eventi](https://www.ictsecuritymagazine.com/eventi/)
* [Newsletter](https://www.ictsecuritymagazine.com/newsletter/)

[Linkedin](https://www.linkedin.com/company/ict-security-magazine/) [YouTube](https://www.youtube.com/%40ictsecuritymagazine1403) [RSS](https://www.ictsecuritymagazine.com/feed/)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

Attiva/disattiva menu

![governance ai](https://www.ictsecuritymagazine.com/wp-content/uploads/governance-ai.jpeg)

# Governance AI e protezione dati: la roadmap EDPS tra accountability e complessità algoritmica

A cura di:[Redazione](#molongui-disabled-link)  Ore 9 Dicembre 202518 Novembre 2025

L’11 novembre 2025 segna una svolta nell’approccio europeo alla governance AI e alla protezione dei dati: il Garante europeo della protezione dei dati (EDPS) ha pubblicato una [guida operativa per il risk management](https://www.edps.europa.eu/data-protection/our-work/publications/guidelines/2025-11-11-guidance-risk-management-artificial-intelligence-systems_en) che, per la prima volta, traduce i principi del GDPR in misure tecniche concrete per i sistemi di intelligenza artificiale. Non si tratta dell’ennesimo documento teorico, ma di un framework operativo basato sulla [metodologia ISO 31000:2018 per la gestione dei rischi](https://www.iso.org/standard/65694.html) che affronta una delle contraddizioni più complesse della trasformazione digitale: come garantire i diritti fondamentali quando i sistemi che elaborano dati personali sono, per loro natura, opachi e probabilistici.

La guida si inserisce in un momento cruciale. Mentre il [Regolamento UE 2024/1689 del 13 giugno 2024](https://eur-lex.europa.eu/eli/reg/2024/1689/oj?locale=it) definisce il perimetro normativo dell’intelligenza artificiale in Europa, rimane aperta la questione su come le organizzazioni possano effettivamente implementare controlli che rispettino il Regolamento 2018/1725 (EUDPR), equivalente del GDPR per le istituzioni UE. La distanza tra requisiti legali e fattibilità tecnica non è mai stata così evidente come nell’ambito dell’AI, dove concetti come “rettifica” o “cancellazione” dei dati personali si scontrano con l’architettura stessa delle reti neurali profonde.

#### **L’illusione della neutralità algoritmica e la tassonomia dei bias**

Il documento dell’EDPS parte da un presupposto raramente esplicitato con questa chiarezza: l’AI non è neutra. I sistemi di machine learning tendono ad amplificare i bias esistenti, incorporando nei loro parametri le distorsioni presenti nei dataset di addestramento. La guida va oltre questa constatazione, proponendo una tassonomia articolata delle fonti di bias che spazia dalla qualità dei dati (*data quality bias*) alla rappresentatività del campione (*sampling bias*), dall’architettura algoritmica (*algorithmic bias*) alle distorsioni interpretative degli analisti umani (*interpretation bias*).

L’approccio è pragmatico e richiede [un sistema di gestione che garantisca applicazione e conformità](https://www.ictsecuritymagazine.com/articoli/e-possibile-una-governance-e-un-controllo-dellai/): l’EDPS non chiede l’impossibile – l’eliminazione totale del bias – ma richiede alle istituzioni di identificarlo, misurarlo e documentare gli sforzi di mitigazione. È un cambio di paradigma rispetto alla compliance formale: non basta dimostrare di aver scelto il fornitore “giusto” o di aver inserito clausole contrattuali appropriate. Serve una comprensione tecnica profonda di come il sistema funziona, quali sono i suoi *failure mode*, dove si annidano i rischi per i diritti delle persone.

#### **La tensione tra performance e data minimisation nel machine learning**

Una delle questioni più delicate riguarda il principio di minimizzazione dei dati nel contesto della governance AI e della protezione dati. I modelli di machine learning, per loro natura, traggono beneficio da grandi quantità di dati: più esempi vedono durante l’addestramento, migliore è – in teoria – la loro capacità di generalizzazione. Ma il [GDPR impone di processare solo dati adeguati](https://gdpr-info.eu/) e pertinenti, limitati a quanto necessario. Come si conciliano queste esigenze?

La guida suggerisce diverse strategie: dal *data sampling* (selezionare sottoinsiemi rappresentativi invece di utilizzare l’intero dataset) all’uso di dati sintetici, dall’anonimizzazione alla pseudonimizzazione. Ma ogni tecnica porta con sé trade-off complessi. I dati sintetici, per esempio, possono preservare la privacy ma rischiano di introdurre nuovi bias o di non catturare pattern marginali ma significativi. L’anonimizzazione, se mal implementata, può essere vulnerabile ad attacchi di re-identificazione, specialmente quando i modelli sono esposti tramite API pubbliche.

Emerge qui una delle tensioni fondamentali della governance AI e della protezione dati: la protezione dei dati non può essere un vincolo esterno aggiunto *a posteriori*, ma deve essere embedded nella progettazione stessa del sistema. Il concetto di *privacy by design* trova nell’AI la sua massima espressione – e la sua massima sfida operativa.

## Explainability e interpretability: i prerequisiti dimenticati nella governance AI

Il documento dedica un’intera sezione a *interpretability* ed *explainability*, definendole come *sine qua non* – prerequisiti essenziali per qualsiasi altra forma di compliance. È una scelta significativa, in linea con [gli strumenti di valutazione d’impatto dell’AI](https://www.ictsecuritymagazine.com/articoli/aiia-intelligenza-artificiale/) che permettono di identificare, analizzare e mitigare i rischi associati ai sistemi automatizzati.

Troppo spesso, la discussione sull’AI si concentra su metriche di performance (accuracy, precision, recall) trascurando la comprensibilità del sistema. Ma senza explainability, come può un’organizzazione verif...