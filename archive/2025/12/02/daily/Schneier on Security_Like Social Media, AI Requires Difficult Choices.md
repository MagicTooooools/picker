---
title: Like Social Media, AI Requires Difficult Choices
url: https://www.schneier.com/blog/archives/2025/12/like-social-media-ai-requires-difficult-choices.html
source: Schneier on Security
date: 2025-12-02
fetch_date: 2025-12-03T03:20:01.356160
---

# Like Social Media, AI Requires Difficult Choices

# [Schneier on Security](https://www.schneier.com/)

Menu

* [Blog](https://www.schneier.com)
* [Newsletter](https://www.schneier.com/crypto-gram/)
* [Books](https://www.schneier.com/books/)
* [Essays](https://www.schneier.com/essays/)
* [News](https://www.schneier.com/news/)
* [Talks](https://www.schneier.com/talks/)
* [Academic](https://www.schneier.com/academic/)
* [About Me](https://www.schneier.com/blog/about/)

### Search

*Powered by [DuckDuckGo](https://duckduckgo.com/)*

Blog

Essays

Whole site

### Subscribe

[![Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com)[Blog](https://www.schneier.com/blog/archives/)

## Like Social Media, AI Requires Difficult Choices

In his 2020 book, “[Future Politics](https://global.oup.com/academic/product/future-politics-9780198825616?cc=ca&lang=en&)*,*” British barrister Jamie Susskind wrote that the dominant question of the 20th century was “How much of our collective life should be determined by the state, and what should be left to the market and civil society?” But in the early decades of this century, Susskind suggested that we face a different question: “To what extent should our lives be directed and controlled by powerful digital systems—and on what terms?”

Artificial intelligence (AI) forces us to confront this question. It is a technology that in theory amplifies the power of its users: A manager, marketer, political campaigner, or opinionated internet user can utter a single instruction, and see their message—whatever it is—instantly written, personalized, and propagated via email, text, social, or other channels to thousands of people within their organization, or millions around the world. It also allows us to individualize solicitations for political donations, elaborate a grievance into a well-articulated policy position, or tailor a persuasive argument to an identity group, or even a single person.

But even as it offers endless potential, AI is a technology that—like the state—gives others new powers to control our lives and experiences.

We’ve seen this out play before. Social media companies made [the same sorts of promises](https://www.technologyreview.com/2024/03/13/1089729/lets-not-make-the-same-mistakes-with-ai-that-we-made-with-social-media/) 20 years ago: instant communication enabling individual connection at massive scale. Fast-forward to today, and the technology that was supposed to give individuals power and influence ended up controlling us. Today social media dominates our [time and attention](https://www.ntu.edu.sg/news/detail/international-study-shows-impact-of-social-media-on-young-people), [assaults our mental health](https://www.hhs.gov/sites/default/files/sg-youth-mental-health-social-media-advisory.pdf), and—together with its Big Tech parent companies—captures an [unfathomable fraction of our economy](https://www.bankrate.com/investing/trillion-dollar-companies/), even as it [poses risks to our democracy](https://www.fastcompany.com/91428050/ai-democracy-insights-to-remember).

The novelty and potential of social media was as present then as it is for AI now, which should make us wary of its potential harmful consequences for society and democracy. We legitimately fear artificial voices and manufactured reality drowning out real people on the internet: on social media, in chat rooms, everywhere we might try to connect with others.

It doesn’t have to be that way. Alongside these evident risks, AI has [legitimate potential](https://mitpress.mit.edu/9780262049948/rewiring-democracy/) to transform both everyday life and democratic governance in [positive ways](https://www.theguardian.com/commentisfree/2025/nov/23/ai-use-strengthen-democracy). In our new book, “[Rewiring Democracy](https://mitpress.mit.edu/9780262049948/rewiring-democracy/),” we chronicle examples from around the globe of democracies using AI to make regulatory enforcement more efficient, catch tax cheats, speed up judicial processes, synthesize input from constituents to legislatures, and much more. Because democracies distribute power across institutions and individuals, making the right choices about how to shape AI and its uses requires both clarity and alignment across society.

To that end, we spotlight four pivotal choices facing private and public actors. These choices are similar to those we faced during the advent of social media, and in retrospect we can see that we made the wrong decisions back then. Our collective choices in 2025—choices made by tech CEOs, politicians, and citizens alike—may dictate whether AI is applied to positive and pro-democratic, or harmful and civically destructive, ends.

### A Choice for the Executive and the Judiciary: Playing by the Rules

The Federal Election Commission (FEC) calls it fraud when a candidate hires an actor to impersonate their opponent. More recently, [they had to decide](https://ash.harvard.edu/articles/whos-accountable-for-ai-usage-in-digital-campaign-ads-right-now-no-one/) whether doing the same thing with an AI deepfake makes it okay. ([They concluded it does not](https://www.fec.gov/updates/commission-approves-notification-of-disposition-interpretive-rule-on-artificial-intelligence-in-campaign-ads/).) Although in this case the FEC made the right decision, this is just one example of how AIs could skirt laws that govern people.

Likewise, courts are having to decide if and when it is okay for an AI to reuse creative materials without compensation or attribution, which might constitute plagiarism or copyright infringement if carried out by a human. (The [court outcomes so far are mixed](https://www.eff.org/deeplinks/2025/02/copyright-and-ai-cases-and-consequences).) Courts are also adjudicating whether corporations are responsible for upholding promises made by AI customer service representatives. (In the case of [Air Canada](https://www.bbc.com/travel/article/20240222-air-canada-chatbot-misinformation-what-travellers-should-know), the answer was yes, and insurers have [started covering the liability](https://www.ft.com/content/1d35759f-f2a9-46c4-904b-4a78ccc027df).)

Social media companies faced many of the same hazards decades ago and [have largely been shielded](https://www.crowell.com/en/insights/client-alerts/the-cda-and-dmca-recent-developments-and-how-they-work-together-to-regulate-online-services) by the combination of Section 230 of the Communications Act of 1994 and the safe harbor offered by the Digital Millennium Copyright Act of 1998. Even in the absence of congressional action to strengthen or add rigor to this law, the Federal Communications Commission (FCC) and the Supreme Court could take action to enhance its effects and to clarify which humans are responsible when technology is used, in effect, to bypass existing law.

### A Choice for Congress: Privacy

As AI-enabled products increasingly ask Americans to share yet more of their personal information—[their “context](https://www.economist.com/by-invitation/2025/09/09/ai-agents-are-coming-for-your-privacy-warns-meredith-whittaker)“—to use digital services like personal assistants, safeguarding the interests of the American consumer should be a bipartisan cause in Congress.

It has been nearly 10 years since Europe adopted comprehensive [data privacy regulation](https://gdpr-info.eu/). Today, American companies exert massive efforts to limit data collection, acquire consent for use of data, and hold it confidential under significant financial penalties—but only for their customers and users in the EU.

Regardless, a decade later the U....