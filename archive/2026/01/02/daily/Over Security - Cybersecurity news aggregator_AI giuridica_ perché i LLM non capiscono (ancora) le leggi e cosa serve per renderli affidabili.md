---
title: AI giuridica: perché i LLM non capiscono (ancora) le leggi e cosa serve per renderli affidabili
url: https://www.cybersecurity360.it/legal/ai-giuridica-perche-i-llm-non-capiscono-ancora-le-leggi-e-cosa-serve-per-renderli-affidabili/
source: Over Security - Cybersecurity news aggregator
date: 2026-01-02
fetch_date: 2026-01-03T03:25:16.254068
---

# AI giuridica: perché i LLM non capiscono (ancora) le leggi e cosa serve per renderli affidabili

[Vai al contenuto principale](#main-content)
[Vai al footer](#footer-content)

![logo](data:image/png;base64...)![logo](https://cdnd360.it/networkdigital360/nd360-neg.svg)

[I NOSTRI SERVIZI](https://www.cybersecurity360.it/about-network)

Menu

[![Vai alla homepage di CyberSecurity](data:image/png;base64...)![Vai alla homepage di CyberSecurity](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2024/03/cybersecurity_logo-768x55.png)](https://www.cybersecurity360.it)

## AI giuridica: perché i LLM non capiscono (ancora) le leggi e cosa serve per renderli affidabili

* [Cybersecurity Nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
* Malware e attacchi
  + [Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
  + [Ransomware](https://www.cybersecurity360.it/nuove-minacce/ransomware/)
* Norme e adeguamenti
  + [Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
  + [Privacy e Dati personali](https://www.cybersecurity360.it/legal/privacy-dati-personali/)
* [Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
* [Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
* [News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
* [Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
* [Chi siamo](https://www.cybersecurity360.it/about/)

* [![Vai alla homepage di CyberSecurity](data:image/png;base64...)![Vai alla homepage di CyberSecurity](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2024/03/cybersecurity_neg_logo-768x55.png)](https://www.cybersecurity360.it)
* Seguici
* + [X](https://twitter.com/Cybersec360)
  + [linkedin](https://www.linkedin.com/company/cybersecurity360/)
  + [Newsletter](https://www.cybersecurity360.it/newsletter-signin/)
  + [Rss Feed](#rssModal)
  + [Chi siamo](https://www.cybersecurity360.it/about)
* AREA PREMIUM
* [Whitepaper](https://www.cybersecurity360.it/whitepaper/)
* [Eventi](https://www.cybersecurity360.it/eventi/)
* [Webinar](https://www.cybersecurity360.it/webinar/)
* CANALI
* [Cybersecurity nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
* [Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
* + [Ransomware](https://www.cybersecurity360.it/nuove-minacce/ransomware/)* [Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
  * + [Privacy e Dati personali](https://www.cybersecurity360.it/legal/privacy-dati-personali/)* [Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
    * [Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
    * [L'esperto risponde](https://www.cybersecurity360.it/esperto-risponde/)
    * [News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
    * [Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
    * [Chi siamo](https://www.cybersecurity360.it/about/)

[Cybersecurity nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
[Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
[Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
[Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
[Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
[L'esperto risponde](https://www.cybersecurity360.it/esperto-risponde/)
[News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
[Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
[Chi siamo](https://www.cybersecurity360.it/about/)

giustizia computazionale

# AI giuridica: perché i LLM non capiscono (ancora) le leggi e cosa serve per renderli affidabili

---

[Home](https://www.cybersecurity360.it)

[Norme e adeguamenti](https://www.cybersecurity360.it/legal/)

---

[Partecipa al dibattito](#comments)

Indirizzo copiato

---

I LLM falliscono sistematicamente nell’interpretazione giuridica: piccole variazioni nei prompt generano risposte opposte. Manca il senso comune giuridico e la stabilità richiesta dal diritto. Per realizzare il mito della “giustizia computazionale” servono modelli verticali, standard rigorosi e controllo umano costante

Pubblicato il 2 gen 2026

---

[Tania Orrù](https://www.cybersecurity360.it/giornalista/tania-orru/)

Privacy Officer e Consulente Privacy

---

---

![AI giuridica LLM affidabilità](data:image/png;base64...)![AI giuridica LLM affidabilità](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2026/01/AI-giuridica.jpg)

---

Negli ultimi anni [l’idea che l’intelligenza artificiale possa contribuire in modo decisivo all’amministrazione della giustizia](https://www.cybersecurity360.it/news/le-sentenze-fantasma-arrivano-in-cassazione-e-fanno-dubitare-della-giustizia/) ha progressivamente abbandonato l’ambito della fantascienza per entrare nel discorso pubblico.

Sistemi di AI sono già utilizzati per il calcolo del rischio di recidiva, per l’allocazione delle risorse giudiziarie, per il supporto alle decisioni amministrative. Con l’avvento dei Large Language Models, questa ambizione si è ulteriormente ampliata andando oltre l’automazione procedurale, per arrivare all’**interpretazione del diritto**.

Avvocati, consulenti legali e talvolta magistrati **sperimentano strumenti come ChatGPT** per ottenere **pareri preliminari**, **verificare la coerenza di un’argomentazione**, **sintetizzare orientamenti giurisprudenziali**. Il linguaggio fluido e persuasivo dei LLM alimenta l’idea che la macchina “capisca” le norme, che possa maneggiare concetti giuridici complessi con una competenza quasi umana.

[Recenti studi](https://www.arxiv.org/abs/2510.25356) mettono radicalmente in discussione questa narrazione: gli autori non si limitano più a segnalare errori o allucinazioni occasionali, ma mostrano come i modelli falliscano sistematicamente nel compito più delicato del diritto, cioè quello di attribuire significato alle norme in modo coerente, stabile e condivisibile.

Il problema è l’**illusione collettiva di una “giustizia computazionale” già pronta per l’uso**. Un’illusione che rischia di produrre più danni che benefici se non viene esaminata e “smontata” con rigore.

> [IA e sentenze fantasma: da condannare l’uso incontrollato dell’intelligenza artificiale](https://www.cybersecurity360.it/legal/ia-e-attivita-legale-limiti-e-rischi/)

Indice degli argomenti

* [Il verdetto dipende dal prompt: l’instabilità strutturale dei LLM](#Il_verdetto_dipende_dal_prompt_linstabilita_strutturale_dei_LLM)
* [Il vero nodo: il senso comune giuridico che la macchina non possiede](#Il_vero_nodo_il_senso_comune_giuridico_che_la_macchina_non_possiede)
* [Perché i modelli generalisti non bastano per il diritto](#Perche_i_modelli_generalisti_non_bastano_per_il_diritto)
* [Verso standard e modelli verticali per l’IA legale](#Verso_standard_e_modelli_verticali_per_lIA_legale)
* [L’instabilità giuridica è anche umana](#Linstabilita_giuridica_e_anche_umana)
* [L’AI Act e il rischio di non conformità](#LAI_Act_e_il_rischio_di_non_conformita)
* [L’interpretazione resta un atto umano (ma può essere assistito)](#Linterpretazione_resta_un_atto_umano_ma_puo_essere_assistito)

## Il verdetto dipende dal prompt: l’instabilità strutturale dei LLM

Il primo risultato empirico degli studi citati è tanto semplice quanto preoccupante: **piccole variazioni nella formulazione di un quesito giuridico generano risposte profondamente diverse**, talvolta opposte. Si tratta di un comportamento ricorrente ed osservabile su più modelli e su diverse tipologie di problemi legali.

Dal punto di vista informatico, questo fenomeno è una conseguenza diretta dell’architettura dei LLM. Il modello non applica regole, non verifica premesse, non deduce conclusioni. Genera invece la **risposta più probabile dato un certo input linguistico**. Il prompting, in questo contesto è un vero e proprio atto di co-costruzione del risultato.

In diversi esperimenti, inoltre, gli LLM producono **h...