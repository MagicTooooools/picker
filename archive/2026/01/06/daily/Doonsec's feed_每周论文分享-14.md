---
title: 每周论文分享-14
url: https://mp.weixin.qq.com/s/0oEuoQlIuiu8NfG9b4u3rw
source: Doonsec's feed
date: 2026-01-06
fetch_date: 2026-01-07T03:31:07.422579
---

# 每周论文分享-14

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhS0u6W1iaexicEZwQUkjBFmAnEFzYauHFeias5XPRpwh2DpMYpfPyPBlVJA/0?wx_fmt=jpeg)

# 每周论文分享-14

物联网与信息安全团队

![]()

在小说阅读器中沉浸阅读

论文分享

    ——2025.1.6

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSEdQXU3OSWyKuFibvYNI5RxLfWqsicPNjmoPicKYibJ3RIzePOc6MZDCxhw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSEdQXU3OSWyKuFibvYNI5RxLfWqsicPNjmoPicKYibJ3RIzePOc6MZDCxhw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSEdQXU3OSWyKuFibvYNI5RxLfWqsicPNjmoPicKYibJ3RIzePOc6MZDCxhw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSEdQXU3OSWyKuFibvYNI5RxLfWqsicPNjmoPicKYibJ3RIzePOc6MZDCxhw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSOmnQLhM1EvKVxxKPfxsiaVahfem6ZO5HKfPiaQFg4IgbtCPO78DgOrRg/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/mmbiz_svg/icTdbqWNOwNQI7xvmWY1kkCKF2ibYiaY3w0UliazQYT87jzHiazVmoib998pdpJbQyCGlZ2cZd4rcm13Tol4tMhC2mgoUNJcyJF7aib/640?wx_fmt=svg&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSyxrpRp4MO287jYpibhEMEH3HlsFAYhQCSp8lBxfuNhnJEPZBnkrsZ8Q/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSvDovMXk9mgWEPtcwjJfqhpibaHgFrS4LpibnibyBEtS4CjcIbmf4DQ4iaQ/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSyxrpRp4MO287jYpibhEMEH3HlsFAYhQCSp8lBxfuNhnJEPZBnkrsZ8Q/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSbrXLiaZyAmjBFn8TaLx4YUWbBWoe152woicgNBquKX3Oj7srENib2uib3w/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSyxrpRp4MO287jYpibhEMEH3HlsFAYhQCSp8lBxfuNhnJEPZBnkrsZ8Q/640?wx_fmt=png&from=appmsg)

标题：Flexible Sharpness-Aware Personalized Federated Learning

CCF-A会： AAAI-2025  CCFA会.

作者：

Xinda Xing, Qiugang Zhan, Xiurui Xie1,Yuning Yang, Qiang Wang, Guisong Liu等

分享人：天津科技大学——黄烈涵

研究方向：个性化联邦学习 (PFL)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSvDovMXk9mgWEPtcwjJfqhpibaHgFrS4LpibnibyBEtS4CjcIbmf4DQ4iaQ/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSbrXLiaZyAmjBFn8TaLx4YUWbBWoe152woicgNBquKX3Oj7srENib2uib3w/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSyxrpRp4MO287jYpibhEMEH3HlsFAYhQCSp8lBxfuNhnJEPZBnkrsZ8Q/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSbrXLiaZyAmjBFn8TaLx4YUWbBWoe152woicgNBquKX3Oj7srENib2uib3w/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSyxrpRp4MO287jYpibhEMEH3HlsFAYhQCSp8lBxfuNhnJEPZBnkrsZ8Q/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSvDovMXk9mgWEPtcwjJfqhpibaHgFrS4LpibnibyBEtS4CjcIbmf4DQ4iaQ/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhS9XOaTe6l5Tk2icl3iakgm0aCVU1V0JBGVE0JsYWPE7XvoaycBcF27wNw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/mmbiz_svg/icTdbqWNOwNQI7xvmWY1kkCKF2ibYiaY3w0yIiczLxtPibzGFfzFz41KryyZ3ia4Wh5AczxkNMl59lzeXhIrG4mZc4hfmYkfUibNPOO/640?wx_fmt=svg&from=appmsg)

**01**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSV1k3bxRXAnJ0aJle23byZSkOibxyKYiczllHbNSGr9e7SVL9z1sLPmJQ/640?wx_fmt=png&from=appmsg)

**研究背景**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSV1k3bxRXAnJ0aJle23byZSkOibxyKYiczllHbNSGr9e7SVL9z1sLPmJQ/640?wx_fmt=png&from=appmsg)

1. 联邦学习中的核心问题：数据异质性

在传统的联邦学习（FL）中，旨在训练一个全局模型。然而，客户端数据通常是非独立同分布（Non-IID）的，这导致单一全局模型难以满足所有客户端的需求。个性化联邦学习（PFL）成为主流，旨在为每个客户端定制模型。

2. 现有方法的局限性

(1) 架构/聚合层面： 现有的PFL方法多集中在模型插值（如FedALA）或参数解耦（如FedCR），侧重于如何利用全局与局部信息。

(2) 优化器层面（SAM）： 近期趋势是将集中式学习中的锐度感知最小化（SAM）引入FL。SAM通过最小化损失和锐度（Sharpness）来寻找平坦极小值，从而提高泛化能力。

(3)现有基于SAM的FL方法的问题： 也就是本文的切入点。

现有的FedSAM或MoFedSAM通常对所有参数施加相同的扰动，或者只是简单地针对特定层（如BN层）操作。理论上，较大的扰动能带来更好的泛化性能（跳出尖锐极小值），但会导致收敛速度变慢甚至不收敛。 神经网络具有层级结构，不同层对扰动的敏感度不同，应该个性化对待。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSEdQXU3OSWyKuFibvYNI5RxLfWqsicPNjmoPicKYibJ3RIzePOc6MZDCxhw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSTX8lVmFAT16RKAAeNicPuKuWksbibsEAY9hyC5gKGTicF5cVSSy3siaeRA/640?wx_fmt=gif&from=appmsg)

**02**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSvDovMXk9mgWEPtcwjJfqhpibaHgFrS4LpibnibyBEtS4CjcIbmf4DQ4iaQ/640?wx_fmt=png&from=appmsg)

**关键技术**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSvDovMXk9mgWEPtcwjJfqhpibaHgFrS4LpibnibyBEtS4CjcIbmf4DQ4iaQ/640?wx_fmt=png&from=appmsg)

在介绍具体算法前，需要明确两个核心概念：

1.锐度感知最小化 (SAM) 的直观理解：

SAM 试图寻找一个不仅当前点损失低，且其邻域内损失都低的区域（平坦极小值）。它通过在参数 上加一个扰动 ，最大化 ，然后更新  以最小化这个最大损失。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSiaCHiaZ9gr6Rsfn3PocGTiaal802HpG37bn1KH7b5KTff09R0FfFoQCVw/640?wx_fmt=png&from=appmsg)

图一：训练损失与锐度图

2.扰动敏感度 (Perturbation Sensitivity)

由于在FL中计算海森矩阵（Hessian）开销太大，本文提出用“扰动敏感度”来近似衡量一层的锐度。

定义：某层参数在施加扰动后，Loss的变化程度。变化越大，说明该层越“尖锐”，即敏感度越高。

3.全局扰动敏感度 (Global Perturbation Sensitivity)

为了避免额外的计算开销（不需要额外的正向/反向传播），作者巧妙地利用了本地训练前后的参数变化来定义敏感度。

逻辑：本地训练过程本身可以看作是对初始全局模型  施加了一个大的“扰动”。

计算公式：第 个客户端第 层的敏感度  近似为：

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSxjvOWEsspc1NOw37cE2KujnyHa9bPaX7G5w8rUOqChaicbs5LMQGBQw/640?wx_fmt=png&from=appmsg)

其中，

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhS29UmZqbqia6cEjLoZO2s3gnlNsMRQAzppMNicamTkk6GZWwFtPhBKIicA/640?wx_fmt=png&from=appmsg)

是本地训练前的全局参数，

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSHHASmYycWdBBXHZVuQlLMziaSAnrhLj7deslrBJ4tC4UicldmAicB2O9w/640?wx_fmt=png&from=appmsg)

是本地训练结束后的参数。

优势：因为这些参数在动量更新或聚合时本来就要计算，所以这个计算几乎是零成本的。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSWyMa98OcAScF3c9ibLlDzuHOJcIsaRIvfuGr9iagQ9kok7S2icBlHNFzw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSTX8lVmFAT16RKAAeNicPuKuWksbibsEAY9hyC5gKGTicF5cVSSy3siaeRA/640?wx_fmt=gif&from=appmsg)

**03**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSFG0G4fNVQjicz7iaicdIHicxYwU4pnQUC39TvNfjcbLTOzMXF19K82Sjpw/640?wx_fmt=png&from=appmsg)

算法介绍FedFSA

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSFG0G4fNVQjicz7iaicdIHicxYwU4pnQUC39TvNfjcbLTOzMXF19K82Sjpw/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSTX8lVmFAT16RKAAeNicPuKuWksbibsEAY9hyC5gKGTicF5cVSSy3siaeRA/640?wx_fmt=gif&from=appmsg)

本文提出的方法名为 FedFSA (Federated Learning with Flexible Sharpness-Aware Minimization)。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSZrPATD7bOPicYcCPT7ibYbZRicuwTZtwTnRnlTx6pMPW3kIQLXGQMmkKA/640?wx_fmt=png&from=appmsg)

图二：FedFSA训练流程图

算法流程如下：

1.  本地训练 (Local Training)：

客户端在进行 SGD 更新时，应用 SAM 优化器。

灵活扰动策略：根据上一轮确定的“关键层”列表：

如果是关键层 (Top-C)：施加较大的扰动 ()。

 如果是普通层：施加默认/较小的扰动 ()。

结合本地动量更新模型。

2. 敏感度评估 (Sensitivity Evaluation)：

在本地训练结束后，客户端计算每层的“全局扰动敏感度”。

对所有层进行排序，选出敏感度最高的  层（Top-C）。

3.  聚合与同步：

服务器聚合模型更新。

客户端将新的 Top-C 列表用于下一轮通信的训练指导。

模型训练伪代码如下图所示：

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSrZqnG9ibVO31nr9pzvYjO4RK0LRweJZqC9ljZAIHDibb3HVXZBHPhEgQ/640?wx_fmt=png&from=appmsg)

图三：FedFSA算法伪代码图

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSWyMa98OcAScF3c9ibLlDzuHOJcIsaRIvfuGr9iagQ9kok7S2icBlHNFzw/640?wx_fmt=png&from=appmsg)

**04**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe4ZRFFAQbEZxoZhSV1k3bxRXAnJ0aJle23byZSkOibxyKYiczllHbNSGr9e7SVL9z1sLPmJQ/640?wx_fmt=png&from=appmsg)

**实验结果分析**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/uG5r3XXT8PLqbGVpe...