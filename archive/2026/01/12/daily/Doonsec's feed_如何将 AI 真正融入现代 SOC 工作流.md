---
title: 如何将 AI 真正融入现代 SOC 工作流
url: https://mp.weixin.qq.com/s/W-so6vYkUl7214-KFnCs4A
source: Doonsec's feed
date: 2026-01-12
fetch_date: 2026-01-13T03:30:59.218124
---

# 如何将 AI 真正融入现代 SOC 工作流

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/w5LtdQbOj8kfhdqExiao9k2JLEkF02skBVeoTsrHJtIVfKSUNuaITRywt27MyXLmhzqWaqOMDiaKt2ibPrX3ejkSw/0?wx_fmt=jpeg)

# 如何将 AI 真正融入现代 SOC 工作流

原创

Zafkie1

SecLink安全空间

![]()

在小说阅读器中沉浸阅读

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/w5LtdQbOj8meb5ndQfobHXbDxp4FfkmCiamTYc6khibickDOarPicD6ic6P1fEQ6BpAPfXSGp3SKrtLzI2Eo5DobPSA/640?wx_fmt=gif&from=appmsg)

全文共计1518字，预计阅读8分钟

这两年，几乎每个 SOC 都在谈 AI。
不管是领导层推动，还是分析员自己用 ChatGPT 写查询、改脚本，AI 已经实实在在进了 SOC。

但有个很现实的问题：

> ❝
>
> **很多团队“在用 AI”，但很少有人说得清楚：
> AI 在 SOC 里，到底算不算一个正式能力？**

从我看到的情况来看，大多数 SOC 的 AI 使用状态都差不多：

* 分析员私下用来改 SPL、写 Python
* 厂商产品里自带一点“AI 功能”，但没人敢全信
* 真正的流程、告警、自动化，还是老样子

SANS 2025 年的 SOC 调研也印证了这一点：
不少组织已经引入 AI，但**并没有把它当成运营体系的一部分**。

问题不在 AI，而在用法。

---

## 一、别指望 AI 帮你“补流程”

我见过最常见的一种想法是：

> ❝
>
> “我们告警太多、规则太乱了，要不加点 AI 吧。”

这是一个**方向就错了的起点**。

如果你的检测逻辑本身不清楚：

* 告警为什么触发说不明白
* 误报从哪来没人管
* 规则上线没验证流程

那 AI 只会让事情变得**更不可控**。

AI 不是来“救火”的，它更像是**放大器**：
流程好的团队，用得更快；
流程差的团队，问题被放得更大。

---

## 二、检测工程：AI 只适合“特别窄”的问题

检测工程里，AI 经常被高估。

真正能落地的 AI 检测，往往有几个共同点：

* 输入数据范围非常明确
* 业务行为非常稳定
* 判断标准可以量化

举个**实际能用**的例子。

有一类检测，只关心 **DNS 流量是不是“真的 DNS”**。
不是判断域名是不是恶意，而是：

> ❝
>
> **这段走 53 端口的流量，长得像不像 DNS？**

一个可落地的做法是：

* 学习大量“正常 DNS 流量”的字节特征
* 新流量进来，看它能不能被正常“复原”
* 复原不了的，直接当异常

这个场景里，AI 是合适的：

* 它不需要理解攻击
* 不需要判断意图
* 只负责识别“陌生感”

但如果你连：

* 告警要解决什么问题
* 谁要用这个告警
* 触发后要不要处理

都没想清楚，那就别急着上 AI。

---

## 三、威胁狩猎：AI 是“放大镜”，不是“裁判”

威胁狩猎本来就不是一个追求“确定性”的事情。

它更像是在做研究：

* 验证一个想法
* 看看某种行为有没有异常
* 判断值不值得做成规则

这个阶段，用 AI 反而是合理的。

分析员可以让 AI：

* 快速扫模式
* 对比历史行为
* 帮你验证一个假设

但有个前提不能丢：

> ❝
>
> **如果分析员自己说不清楚
> “这东西为什么值得关注”，
> 那 AI 发现得再“奇怪”，也没意义。**

AI 只能帮你跑得快，
方向还是得人来定。

---

## 四、写代码这件事，AI 很好用，也很危险

现在 SOC 里，几乎没人不写代码了：

* Python 拉日志、算时间、打标签
* PowerShell 查主机状态
* SPL / EQL 调查询

说实话，**AI 在这块是真的好用**。

但问题也正出在这：

> ❝
>
> **AI 写的代码，看起来往往“非常像对的”。**

如果分析员：

* 不理解这段代码的副作用
* 没测试就丢进生产
* 甚至不知道它在调用什么库

那风险会比人工写还高。

比较稳妥的做法是：

* 明确代码规范
* 限定可用库
* 把这些要求写进 Prompt 里
* 把 AI 当“实习生”，不是“专家”

---

## 五、自动化：流程可以交给 AI，决定权不行

AI 很适合做一件事：
**把“人话”翻译成自动化流程。**

比如：

* 根据 Runbook 生成 SOAR 流程骨架
* 帮你补条件分支
* 帮你理清上下游关系

但有一条红线一定要守住：

> ❝
>
> **什么时候执行动作，必须是人决定的。**

是否：

* 隔离主机
* 禁用账号
* 封 IP

这些不是技术问题，是**风险问题**。

自动化的信任，来自于：

* 长时间测试
* 人对结果的理解
* 一次次复盘积累

而不是 AI 自己“算出来的”。

---

## 六、最适合 AI 的地方，其实是写报告

说句实话，
**SOC 最拖累人的工作之一，就是写报告。**

不是不会写，是：

* 太重复
* 太花时间
* 每个人风格还不一样

这恰恰是 AI 最稳、风险最低的应用场景。

它可以帮你：

* 统一结构
* 把杂乱笔记整理成一段话
* 把技术细节翻译成管理能看懂的版本

只要你给的事实是对的，
AI 基本不会“乱来”。

---

## 最后总结一下

AI 在 SOC 里，不是越多越好，也不是越“智能”越好。

真正有用的 AI，往往具备几个特征：

* 问题范围小
* 结果能验证
* 出问题能兜底
* 人能解释它在干什么

如果你现在的 SOC 还在：

* 理流程
* 建规范
* 控告警质量

那 **先把这些事做好，再谈 AI**，一点也不晚。

请关注**SecLink安全空间**获取我们最新的更新

欢迎加入**SecLink安全空间**微信群探讨安全问题！

![](https://mmbiz.qpic.cn/sz_mmbiz_png/w5LtdQbOj8lWZiaxTq4Y8spYawkEdXhwsXR6n5Y5ok1dsxvZb25oY38UAD9V0jMMJJnOiaVqz2p19U8V4Goib9u4Q/640?wx_fmt=png&from=appmsg)

预览时标签不可点

![]()

微信扫一扫
关注该公众号

继续滑动看下一个

轻触阅读原文

![](http://mmbiz.qpic.cn/sz_mmbiz_png/w5LtdQbOj8n5Ma1w6bISsXfGFynBD1cxlrRm33Wq7Kia8MTiaUiaWNATKIVIRsdARKHAE6htC6iapEibYPOgjia8WdyQ/0?wx_fmt=png)

SecLink安全空间

向上滑动看下一个

知道了

![]()
微信扫一扫
使用小程序

取消
允许

取消
允许

取消
允许

×
分析

![跳转二维码]()

![作者头像](http://mmbiz.qpic.cn/sz_mmbiz_png/w5LtdQbOj8n5Ma1w6bISsXfGFynBD1cxlrRm33Wq7Kia8MTiaUiaWNATKIVIRsdARKHAE6htC6iapEibYPOgjia8WdyQ/0?wx_fmt=png)

微信扫一扫可打开此内容，
使用完整服务

：
，
，
，
，
，
，
，
，
，
，
，
，
。

视频
小程序
赞
，轻点两下取消赞
在看
，轻点两下取消在看
分享
留言
收藏
听过